"""
è¯»å–ç«è½¦å¤´é‡‡é›†å™¨ä¸­çš„æ•°æ®,å¹¶å°†å…¶å†™å…¥åˆ°sqliteæ•°æ®åº“ä¸­
æ¨¡å—é‡‡ç”¨äº†æ—¥å¿—loggingæ¨¡å—è¿›è¡Œæ—¥å¿—è®°å½•
ä½¿ç”¨woosqlitedbä½œä¸ºæ—¥å¿—å,å¤–éƒ¨è°ƒç”¨è€…å¯ä»¥åˆ›å»ºæ­¤åç§°çš„æ—¥å¿—è®°å½•å™¨,ä»è€Œä¿®æ”¹æ—¥å¿—è¡Œä¸º(æ¯”å¦‚æ—¥å¿—çº§åˆ«)

"""

import csv
import os
import re
import shutil
import sqlite3
import sys
import threading
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import time

# from logging import debug, error, info, warning
from pathlib import Path
from tqdm import tqdm

import pandas as pd

from comutils import (
    SUPPORT_IMAGE_FORMATS_NAME,
    complete_image_file_extension,
    count_lines_csv,
    get_filebasename_from_url,
    remove_sensitive_info,
    set_image_extension,
    split_urls,
    get_now_time_str,
)

from filenamehandler import FilenameHandler
from wooenums import CSVProductFields, DBProductFields, ImageMode, LanguagesHotSale

IMAGES = CSVProductFields.IMAGES.value
IMAGE_URL = CSVProductFields.IMAGES_URL.value
DEFAULT_TABLE = "Content"
MAX_IMG_NAME_LENGTH = 100


def set_log(name=__name__):
    """é…ç½®æ¨¡å—çº§çš„æ—¥å¿—å¯¹è±¡
    åŒ…æ‹¬é»˜è®¤çš„æ—¥å¿—æ ¼å¼å’Œæ—¥å¿—çº§åˆ«(WARNING)
    é»˜è®¤è¿”å›console handler

    Args:
        name (str, optional): æ—¥å¿—åç§°. Defaults to __name__.

    Returns:
        logging.Logger: æ—¥å¿—å¯¹è±¡
    """
    lgr = logging.getLogger(name)
    lgr.setLevel(logging.WARNING)
    # ä½œä¸ºä¸€ä¸ªæ¨¡å—,å¯ä»¥ä¸æ˜¾å¼è®¾ç½®Handlerå’ŒFormatter
    formatter = logging.Formatter(
        fmt="[%(levelname)s] %(name)s:%(module)s.%(funcName)s-%(message)s"  # %(asctime)s:%(lineno)d
    )
    # fh=logging.FileHandler("woosqlitedb.log", mode="a", encoding="utf-8")
    ch = logging.StreamHandler()
    ch.setFormatter(formatter)
    # ch.setLevel(logging.WARNING)
    # ä½œä¸ºä¸€ä¸ªæ¨¡å—,ä¸€èˆ¬ä¸è®¾ç½®æ—¥å¿—æ–‡ä»¶handler
    # fh=logging.FileHandler("woosqlitedb.log", mode="a", encoding="utf-8")
    lgr.addHandler(ch)
    return lgr


# é…ç½®æ—¥å¿—ç¼©å†™
logger = set_log(__name__)

debug = logger.debug
info = logger.info
warning = logger.warning
error = logger.error


fnh = FilenameHandler()
csv.field_size_limit(int(1e7))  # è®¾ç½®ä¸º 10MB æˆ–æ›´é«˜ï¼ˆå•ä½ï¼šå­—èŠ‚ï¼‰

# å°åˆ†ç±»é˜ˆå€¼,å°äºè¯¥é˜ˆå€¼çš„åˆ†ç±»å°†è¢«è§†ä¸ºå°åˆ†ç±»
SMALL_CATEGORY_THRESHOLD = 30
# é…ç½®åˆ‡å‰²ä¸åŒurlçš„åˆ†éš”ç¬¦(å°å¿ƒé€‰æ‹©åˆ†éš”ç¬¦,ä¾‹å¦‚é€—å·å’Œåˆ†å·ç”šè‡³æ˜¯ç©ºæ ¼,éƒ½æ˜¯æœ‰å¯èƒ½å‡ºç°åœ¨urlä¸­çš„),è¿™é‡Œé€‰æ‹©">"ä½œä¸ºåˆ†éš”ç¬¦
SEPARATOR = ">"
LOWEST_PRICE = 1
HIGHEST_PRICE = 10000
cnt_lock = threading.Lock()


def check_df_empty(df):
    """æ£€æŸ¥dataframeæ•°æ®æ˜¯å¦ä¸ºç©º"""
    if df.shape[0] == 0:
        print("No data in dataframe, skip processing.")
        return True
    else:
        return False


def update_image_fields_from_legacy(csv_file):
    """æ›´æ–°å›¾ç‰‡å­—æ®µ
    é’ˆå¯¹åªæœ‰Imageså­—æ®µä½†æ˜¯ç¼ºå¤±ImagesUrlå­—æ®µçš„äº§å“å›¾ç‰‡å­—æ®µæ›´æ–°/è¡¥å…¨å®Œæ•´(ä¸»è¦ä¸ºå…¼å®¹è€csvæ ¼å¼å‡†å¤‡çš„)
    è¿™ç§é‡Œé’ˆå¯¹ImagesåŒ…å«äº†å›¾ç‰‡urlçš„æƒ…å†µï¼Œç„¶åImagesUrlå­—æ®µå–ä»£Imageså­—æ®µï¼ŒImageså­—æ®µä¼šæ›´æ–°ä¸ºå›¾ç‰‡å

    """
    df = pd.read_csv(csv_file)
    # å¦‚æœdfä¸­ä¸€è¡Œæ•°æ®éƒ½æ²¡æœ‰,åˆ™è·³è¿‡
    if check_df_empty(df):
        return False
    # fh = FilenameHandler()
    if IMAGE_URL in df.columns and df[IMAGE_URL].notnull().any():
        print("ImagesUrl field already exists, no need to update.")
        return False  # ç›¸å…³å­—æ®µå·²ç»å­˜åœ¨,ä¸éœ€è¦æ›´æ–°
    df[IMAGE_URL] = df[IMAGES]
    df[IMAGES] = df[IMAGES].apply(fnh.get_filename_from_url)
    df.to_csv(csv_file, index=False)


def update_image_fields(csv_dir):
    """å°†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„csvæ–‡ä»¶ä¸­çš„å›¾ç‰‡å­—æ®µæ›´æ–°
    å¾ªç¯è°ƒç”¨ `update_image_fields_from_legacy` å‡½æ•°æ›´æ–°æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„csvæ–‡ä»¶ä¸­çš„å›¾ç‰‡å­—æ®µ

    """
    print(csv_dir)
    for file in os.listdir(csv_dir):
        file = os.path.abspath(os.path.join(csv_dir, file))

        # print(file)
        # update_image_fields(file)
        if file.endswith(".csv"):
            print(f"Updating image fields for:{file} ")
            update_image_fields_from_legacy(file)


def update_image_fields_extension(csv_dir, extension=".webp"):
    """å°†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„csvæ–‡ä»¶ä¸­çš„å›¾ç‰‡å­—æ®µçš„å€¼çš„åç¼€åæ”¹ä¸ºæŒ‡å®šæ ¼å¼"""
    print(csv_dir)
    dfs = []
    for file in os.listdir(csv_dir):
        file = os.path.abspath(os.path.join(csv_dir, file))
        if file.endswith(".csv"):
            print(f"Updating image fields extension for:{file} ")
            df = pd.read_csv(file)
            if check_df_empty(df):
                continue
            # å¦‚æœåŸåç¼€æ˜¯å¸¸è§å›¾ç‰‡æ ¼å¼,æ¯”å¦‚jpg,png,gif,webp,tif,gifè¿™ç§åˆ™æ›¿æ¢åç¼€ä¸ºæŒ‡å®šæ ¼å¼
            df[IMAGES] = set_image_extension(
                df[IMAGES],
                default_image_format=extension,
                supported_image_formats=SUPPORT_IMAGE_FORMATS_NAME,
            )

            # df[IMAGES] = df[IMAGES].str.rsplit(".", n=1).str[0] + f".{extension}"
            # æ‰“å°å‰10è¡ŒæŸ¥çœ‹ä¿®æ”¹æ•ˆæœ
            print(df.head(10))
            dfs.append(df)
            df.to_csv(file, index=False)
    return dfs


def remove_items_without_img(csv_dir, img_dir, backup_dir="backup_csvs"):
    """åˆ é™¤csvæ–‡ä»¶ä¸­æ²¡æœ‰å›¾ç‰‡çš„äº§å“

    Args:
        csv_dir (str): csvæ–‡ä»¶æ‰€åœ¨ç›®å½•
        backup_dir (str, optional): å¤‡ä»½ç›®å½•,å¦‚æœä¸ºç©ºä¸²,åˆ™ä¸å¤‡ä»½. Defaults to "".

    """
    print(csv_dir)
    for file in os.listdir(csv_dir):
        file = os.path.abspath(os.path.join(csv_dir, file))
        if file.endswith(".csv"):
            print(f"Removing items without image for:{file} ")
            df = pd.read_csv(file)
            if check_df_empty(df):
                continue
            # æ ¹æ®éœ€è¦å¤‡ä»½æ–‡ä»¶
            if backup_dir:
                # å¤åˆ¶æ–‡ä»¶fileåˆ°backup_dirç›®å½•ä¸‹å¤‡ç”¨

                os.makedirs(backup_dir, exist_ok=True)  # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
                backup_file_path = os.path.join(backup_dir, os.path.basename(file))
                shutil.copy(file, backup_file_path)  # å¤åˆ¶æ–‡ä»¶åˆ°å¤‡ä»½ç›®å½•
            # åˆ¤æ–­æ¯ä¸ªIMAGEå­—æ®µä¸­çš„å›¾ç‰‡åœ¨æŒ‡å®šç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨,ä¸å­˜åœ¨çš„è¿‡æ»¤ç§»é™¤
            df = df[
                df[IMAGES].apply(
                    lambda x: os.path.exists(os.path.join(img_dir, str(x)))
                )
            ]

            # å°†è¿‡æ»¤åçš„æ•°æ®ä¿å­˜å›åŸæ–‡ä»¶
            df.to_csv(file, index=False)


def process_image_csv(img_dir, csv_dir, backup_dir="backup_csvs"):
    """æ›´æ–°CSVæ–‡ä»¶ä¸­çš„å›¾ç‰‡å­—æ®µ,è®¾ç½®æ ¼å¼ä¸ºwebp,å¹¶ç§»é™¤æ— å›¾ç‰‡çš„æ¡ç›®
    è¯·åŠ¡å¿…å›¾ç‰‡ä¸‹è½½å®Œæ¯•åå†æ‰§è¡Œæœ¬å¤„ç†,å¦åˆ™csvæ–‡ä»¶å†…å®¹å°†å› ä¸ºå›¾ç‰‡æ‰¾ä¸åˆ°è€Œå…¨éƒ¨è¢«ç§»é™¤

    é»˜è®¤æƒ…å†µä¸‹æ‰§è¡Œæ­¤å‡½æ•°ä¼šè¿›è¡Œå¤‡ä»½,å› æ­¤å¦‚æœæ¸…ç©ºå¤ªå¤šå›¾ç‰‡,åˆ™å¯ä»¥æ¢å¤å¤‡ä»½æ–‡ä»¶

    """
    csv_dir = os.path.abspath(csv_dir)  # è®¡ç®—ç»å¯¹è·¯å¾„
    print(csv_dir)

    total_before = count_lines_csv(csv_dir)

    update_image_fields(csv_dir)
    update_image_fields_extension(csv_dir, extension=".webp")

    # return # debug
    remove_items_without_img(csv_dir, img_dir=img_dir, backup_dir=backup_dir)

    if backup_dir:
        cwd = os.getcwd()
        backup_dir = os.path.abspath(os.path.join(cwd, backup_dir))  # è®¡ç®—ç»å¯¹è·¯å¾„
        print("=" * 50)
        print(f"csvæ–‡ä»¶å¤‡ä»½åˆ°{backup_dir}ğŸˆ")
        print("=" * 50)
    total_after = count_lines_csv(csv_dir)
    print(f"å¤„ç†åå‰©ä½™{total_after}æ¡æ•°æ®,å‡å°‘äº†{total_before - total_after}æ¡æ•°æ®")


class SQLiteDB:
    """sqliteæ•°æ®åº“æ“ä½œç±»
    æ ¹æ®ä¸šåŠ¡éœ€è¦,è¿™é‡Œä¸»è¦ä»¥è¯»å–æ“ä½œä¸ºä¸»,å…¶ä»–æ“ä½œå¯ä»¥åæœŸæŒ‰éœ€æ‰©å±•

    """

    def __init__(
        self,
        language="US",
        category_threshold=SMALL_CATEGORY_THRESHOLD,
        lowest_price=LOWEST_PRICE,
        highest_price=HIGHEST_PRICE,
        max_img_name_length=MAX_IMG_NAME_LENGTH,
        desc_min_len=0,
        # å¦‚æœäº§å“æè¿°å­—ç¬¦å¾ˆçŸ­,åˆ™å°†äº§å“åç§°(æ ‡é¢˜)ä½œä¸ºäº§å“æè¿°
        name_as_desc=True,
        yy=False,
    ):
        self.language = language
        self.yy = yy
        self.desc_min_len = desc_min_len
        self.name_as_desc = name_as_desc
        # é»˜è®¤ç¼“å­˜å˜é‡(ä»DBæ–‡ä»¶ä¸­è¯»å–)
        self.field_names_full = DBProductFields.get_all_fields_name(
            exclude_field=DBProductFields.SKU.name
        )
        self.field_values_full = DBProductFields.get_all_fields_value(
            exclude_field=DBProductFields.SKU.value
        )
        self.max_img_name_length = max_img_name_length
        self.lowest_price = lowest_price
        self.highest_price = highest_price
        self.category_threshold = category_threshold
        # ç¼“å­˜ä»æ•°æ®åº“ä¸­è¯»å‡ºæ¥çš„æ•°æ®è¡Œ(è®°å½•),é»˜è®¤æƒ…å†µä¸‹ä»…å­˜å‚¨ä¸šåŠ¡éœ€è¦çš„è¡Œä»¥åŠå­—æ®µ
        self.db_rows = []
        # self.data_dict_rows = []
        # ç»Ÿè®¡å„ä¸ªæ•°æ®åº“è¯»å…¥çš„å¯ç”¨æ•°æ®è¡Œæ•°
        self.db_reports = {}
        # å…·æœ‰å±æ€§å€¼çš„äº§å“ç¼“å­˜(db rowå¯¹è±¡)
        self.products_with_attribute = []
        # ä¿å­˜ç®€åŒ–å­—æ®µçš„å­—å…¸(name,sku,attribute_values,page_url)
        self.attribute_checker = []
        # è®°å½•æ˜¾ç„¶ä¸è§„èŒƒçš„å±æ€§å€¼äº§å“(db_rowsçš„å­é›†)
        self.invalid_attribute_subset = []
        # é€ŸæŸ¥å±æ€§å€¼ä¸è§„èŒƒçš„äº§å“åˆ—è¡¨ç´¢å¼•
        self.invalid_index_dict = {}
        # è®°å½•å¯èƒ½ä¸è§„èŒƒçš„å±æ€§å€¼çš„äº§å“
        self.invalid_attribute_supperset = []
        # åˆ†ç±»ç»Ÿè®¡
        self.category_statistic = {}
        self.attr_subset_pattern = re.compile(r".*#.*")
        self.attr_superset_pattern = re.compile(
            r".*#.*[|>].*"
        )  # ä¸ºäº†å…¼å®¹|,>ä¸¤ç§ç¬¦å·åˆ†å‰²å±æ€§é€‰é¡¹
        # å¤„ç†è¿›åº¦(äº§å“æ•°æ®æ¡æ•°)
        self.progress = 0
        # å¯ç”¨ WAL æ¨¡å¼å’Œ PRAGMA è®¾ç½®ä»¥ä¼˜åŒ–æ€§èƒ½
        self.pragma_settings = {
            "journal_mode": "WAL",
            "synchronous": "NORMAL",
            "cache_size": -10000,
        }
        # è®¡ç®—æ‰¹æ¬¡æ—¶é—´æˆ³
        self.stamp = int(time.time())

    # def close_db(self):
    #     """å…³é—­æ•°æ®åº“è¿æ¥"""
    #     self.conn.close()

    def get_selected_fields(
        self,
        connection,
        table=DEFAULT_TABLE,
        empty_check=True,
        fields="",
        where=None,
        params=None,
        batch_size=1000,
        as_iterator=False,
    ):
        """
        è·å–è¡¨ä¸­æŒ‡å®šå­—æ®µ

        :param connection: æ•°æ®åº“è¿æ¥
        :param table: è¡¨å
        :param fields: å­—æ®µåˆ—è¡¨æˆ–å­—ç¬¦ä¸²
        :param where: WHEREæ¡ä»¶è¯­å¥ï¼ˆä¸å«WHEREå…³é”®å­—ï¼‰
        :param params: æ¡ä»¶å‚æ•°
        :param empty_check: æ˜¯å¦è¿‡æ»¤æ‰æ•°æ®åº“ä¸­ç©ºè¡Œ(æ¯”å¦‚æ²¡æœ‰äº§å“åç§°ä¸ºç©ºçš„è¡Œ)
        :param batch_size: æ¯æ‰¹è¯»å–çš„è¡Œæ•° (é»˜è®¤1000)
        :param as_iterator: æ˜¯å¦è¿”å›ç”Ÿæˆå™¨è¿­ä»£å™¨ (é»˜è®¤ä¸ºFalseï¼Œä¿æŒå…¼å®¹æ€§)
        :return: ç»“æœåˆ—è¡¨ æˆ– ç”Ÿæˆå™¨è¿­ä»£å™¨
        """
        # æ„é€ æŸ¥è¯¢è¯­å¥
        if not fields:
            fields = self.field_values_full

        if isinstance(fields, (list, tuple)):
            fields_str = ", ".join(fields)
        else:
            fields_str = fields

        sql = f"SELECT {fields_str} FROM {table}"

        # æ·»åŠ WHEREæ¡ä»¶
        if where:
            sql += f" WHERE {where}"

        # è·å–æŸ¥è¯¢æ¸¸æ ‡(ä½¿ç”¨å®Œè®°å¾—å…³é—­æ¸¸æ ‡)
        cursor = connection.cursor()

        cursor.execute(sql, params or ())

        # åˆ†æ‰¹å¤„ç†å‡½æ•°
        def process_batch():
            while True:
                # è·å–ä¸€æ‰¹æ•°æ®
                rows = cursor.fetchmany(batch_size)
                if not rows:
                    break

                # ç©ºè¡Œæ£€æŸ¥
                if empty_check:
                    name_field = DBProductFields.NAME.value
                    rows = [row for row in rows if row[name_field]]

                yield rows

        # æµå¼å¤„ç†æ¨¡å¼ï¼šè¿”å›ç”Ÿæˆå™¨
        if as_iterator:
            return process_batch()

        # å…¼å®¹æ¨¡å¼ï¼šä¸€æ¬¡æ€§è¿”å›ç”Ÿæˆå™¨ä¸­çš„æ‰€æœ‰æ•°æ®(è€—å°½ç”Ÿæˆå™¨)
        rows = []
        if batch_size > 0:
            # åˆ†æ‰¹è¯»å–å¹¶åˆå¹¶ç»“æœ
            for batch in process_batch():
                rows.extend(batch)
            return rows

        # æ™®é€šæ¨¡å¼ï¼šä¸€æ¬¡æ€§è¯»å–æ‰€æœ‰æ•°æ®(ä½¿ç”¨fetchall()ä¸€æ¬¡æ€§è¯»å–æ‰€æœ‰æ•°æ®)
        # rows = cursor.fetchall()

        # è½¬æ¢Rowå¯¹è±¡ä¸ºå¯å†™çš„å­—å…¸
        # rows = [dict(row) for row in rows]
        if empty_check:
            name_field = DBProductFields.NAME.value
            rows = [row for row in rows if row.get(name_field)]
        # å…³é—­æ¸¸æ ‡
        cursor.close()
        return rows

    def get_data_init(
        self, db_path, fields="", strict_mode=False, count_rows_only=False
    ):
        """ä»å•ä¸ªæ•°æ®åº“è·å–åˆæ­¥å¤„ç†è¿‡çš„æ•°æ®

        æ­¤å‡½æ•°è°ƒç”¨get_data_from_db()è·å–æ‰€æœ‰ç‰¹å®šå­—æ®µçš„è¡Œ

        Args:
            db_path: sqliteæ–‡ä»¶è·¯å¾„
            fields: éœ€è¦æŸ¥è¯¢çš„å­—æ®µåˆ—è¡¨æˆ–å­—ç¬¦ä¸²
            strict_mode:æ˜¯å¦åªæ ¹æ®äº§å“åå»é‡(å¦‚æœæ˜¯ä»…æ ¹æ®åŒåäº§å“è€Œä¸è€ƒè™‘å›¾ç‰‡é“¾æ¥,å¯èƒ½é€ æˆæ•°æ®å¤§å¤§å‡å°‘)
            count_rows_only:æ˜¯å¦åªè¿”å›è¡Œæ•°,ä¸è¿”å›æ•°æ®,ç”¨äºå¿«é€Ÿç»Ÿè®¡é‡‡é›†çš„æ•°æ®æœ‰å¤šå°‘
        """
        info("read data from %s...", db_path)
        rows = []
        unique_rows = []
        try:
            rows = self.get_data_from_db(db_path, fields)
            # Rowå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
            rows = [dict(row) for row in rows]
            if count_rows_only:
                self.db_reports[db_path] = {
                    "total_raw": len(list(rows)),
                    "total_unique": None,
                }
                return []

        except sqlite3.Error as e:
            error(
                "Jump process:[%s] file is not a valid db file. Error: %s", db_path, e
            )
            return []
        else:
            # åˆæ­¥æ•°æ®å¤„ç†æ“ä½œ

            unique_rows = self.clean_rows(db_path, rows, strict_mode=strict_mode)

            # print(handler_dict)
        self.db_reports[db_path] = {
            "total_raw": len(list(rows)),
            "total_unique": len(unique_rows),
        }
        return unique_rows

    def clean_rows(self, db_path, rows, strict_mode=False):
        """æ¸…ç†ä¸åˆé€‚çš„äº§å“
        æ¯”å¦‚,äº§å“å»é‡å¤,ç§»é™¤å­—ç¬¦äº§å“åå¼‚å¸¸(æ¯”å¦‚å¾ˆå¤šé—®å·)çš„äº§å“ç­‰
        äº§å“å»é‡å¯ä»¥ä½¿ç”¨pandasåº“ç®€å•å®ç°,è¿™é‡Œæ—©èµ·æ²¡æœ‰ä½¿ç”¨pandas,ä¿ç•™ä½¿ç”¨åŸç”Ÿçš„æ–¹å¼å¤„ç†
        é»˜è®¤æƒ…å†µä¸‹,äº§å“åå’Œå›¾ç‰‡åŒæ—¶é‡å¤çš„è®°å½•åªä¿ç•™ä¸€æ¡(ä»…æ’é™¤ä¸¤è€…éƒ½é‡å¤çš„æƒ…å†µ)
        å¦‚æœä¸¥æ ¼æ¨¡å¼,åˆ™ä»…æ¯”è¾ƒäº§å“å,å¿½ç•¥å›¾ç‰‡çš„æ¯”è¾ƒ

        è®¿é—®å†…å­˜ä¸­çš„æ•°æ®è¡Œ
        handler_dict # å­˜å‚¨å•å…ƒç»“æ„: {product_img: {product_name: count}}çš„ç»“æ„
        # æƒ³è¦è®¿é—®count,è¡¨è¾¾å¼ä¸ºhandler_dict[product_img][product_name]

        Args:
            db_path: sqliteæ–‡ä»¶è·¯å¾„
            rows: æ•°æ®åº“è¡Œæ•°æ®
            strict_mode:æ˜¯å¦åªæ ¹æ®äº§å“åå»é‡
                ä¸ºTrueæ—¶æ¯”è¾ƒä¸¥æ ¼(ä¸å…è®¸åŒåäº§å“å­˜åœ¨,å“ªæ€•å›¾ç‰‡é“¾æ¥ä¸ä¸€æ ·ä¹Ÿè¦ç§»é™¤),å¯èƒ½ä¼šè¯¯ä¼¤è®¸å¤šäº§å“æ•°æ®(ä½†æ˜¯è¿™ç§äº§å“ç›¸ä¼¼åº¦åº¦é«˜,æ•ˆæœå¯èƒ½ä¸å¥½ä¸€èˆ¬ä¹Ÿä¸å»ºè®®ä¿ç•™)
                (å¦‚æœä¸ºFalse,åˆ™åªå½“äº§å“åå’Œå›¾ç‰‡é“¾æ¥åŒæ—¶é‡å¤æ‰å»é‡,ä¼šä¿ç•™æ›´å¤šæ•°æ®,ä½†æ˜¯å¯¹äºè·¨ç«™äº§å“é‡å¤çš„æƒ…å†µæ— æ³•è‰¯å¥½å¤„ç†)
        """

        unique_rows = []
        dd = defaultdict(dict)  # è®¿é—®ddçš„æŸä¸ªå°šä¸å­˜åœ¨çš„å±æ€§(key)æ—¶,ä¼šè¿”å›ä¸€ä¸ªdict

        name_field = DBProductFields.NAME.value
        img_field = DBProductFields.IMAGES.value
        desc_field = DBProductFields.DESCRIPTION.value

        # æ·»åŠ tqdmè¿›åº¦æ¡ï¼Œæ˜¾ç¤ºç™¾åˆ†æ¯”
        for i, row in tqdm(
            enumerate(rows), total=len(rows), desc="å»é‡è¿›åº¦", unit="è¡Œ"
        ):
            product_name = row[name_field]
            product_img = row[img_field]
            product_desc = row[desc_field]
            # product_info = f"{{name:{product_name};sku:{product_sku}}}"
            # names_dict = dd.get(product_img, {})
            # names=dd[product_img]
            product_img_dict = dd[product_name]

            # è¿›åº¦è®¡æ•°å™¨
            with cnt_lock:
                self.progress += 1
                debug("progress: {{%s}}", self.progress)
                # print(f"progress: {self.progress}")
                # æ£€æŸ¥é‡å¤

            # è·å–å¤„ç†è¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯
            # æ•°æ®åº“æ–‡ä»¶æ‰€åœ¨çˆ¶ç›®å½•çš„ç¼–å·åç§°
            dbp = Path(db_path)
            db_id = dbp.parent.name
            # å»é‡ç­–ç•¥
            if (strict_mode and product_img_dict) or (product_img in product_img_dict):
                self.duplicate_warning(i, row, db_id)
                continue
            # if strict_mode and product_img_dict:
            #     self.duplicate_warning(i, row, db_id)
            #     continue
            # if product_img in product_img_dict:
            #     self.duplicate_warning(i, row, db_id)
            #     continue
            else:
                # å¦‚æœäº§å“æè¿°é•¿åº¦ä¸è¶³è¦æ±‚,åˆ™æ ¹æ®æƒ…å†µç”¨äº§å“åç§°è¦†ç›–(ä»£æ›¿æè¿°)æˆ–è€…ä¸¢å¼ƒæ­¤æ¡æ•°æ®
                if self.desc_min_len and len(product_desc) < self.desc_min_len:
                    warning(
                        "product:[%s] description length is less than %s",
                        i,
                        self.desc_min_len,
                    )
                    if "???" in row[name_field]:
                        warning("product:[%s] name contains consecutive question mark!", i)
                        continue

                    if self.name_as_desc:
                        row[desc_field] = product_name
                        info("product:[%s] description is replaced by product name", i)
                    else:
                        warning("product:[%s] record is dropped.", i)
                        continue
                # å½“å‰äº§å“å°šæœªç»Ÿè®¡è¿‡,æ›´æ–°ç»Ÿè®¡è®¡æ•°å™¨
                unique_rows.append(row)
                info(
                    "keep:product:[%s] of [%s db]: duplicated name, \
    but different image, keep records [%s]",
                    i,
                    db_id,
                    (row[name_field], row[img_field]),
                )

            # dd[product_img][product_name] = dd[product_img].get(product_name, 0) + 1
            dd[product_name][product_img] = dd[product_name].get(product_img, 0) + 1

        return unique_rows

    def process_forbidden_words(self, s, pattern=".php", replacement="_"):
        """æ›¿æ¢å­—ç¬¦ä¸²ä¸­åŒ…å«çš„ç¦è¯"""
        return re.sub(pattern, replacement, s)

    def remove_duplicate_rows_deprecated(self, db_path, rows, strict_mode=False):
        """äº§å“å»é‡:
        é»˜è®¤æƒ…å†µä¸‹,äº§å“åå’Œå›¾ç‰‡åŒæ—¶é‡å¤çš„è®°å½•åªä¿ç•™ä¸€æ¡(ä»…æ’é™¤ä¸¤è€…éƒ½é‡å¤çš„æƒ…å†µ)
        å¦‚æœä¸¥æ ¼æ¨¡å¼,åˆ™ä»…æ¯”è¾ƒäº§å“å,å¿½ç•¥å›¾ç‰‡çš„æ¯”è¾ƒ

        è®¿é—®å†…å­˜ä¸­çš„æ•°æ®è¡Œ
        handler_dict # å­˜å‚¨å•å…ƒç»“æ„: {product_img: {product_name: count}}çš„ç»“æ„
        # æƒ³è¦è®¿é—®count,è¡¨è¾¾å¼ä¸ºhandler_dict[product_img][product_name]

        Args:
            db_path: sqliteæ–‡ä»¶è·¯å¾„
            rows: æ•°æ®åº“è¡Œæ•°æ®
            strict_mode:æ˜¯å¦åªæ ¹æ®äº§å“åå»é‡
                ä¸ºTrueæ—¶æ¯”è¾ƒä¸¥æ ¼(ä¸å…è®¸åŒåäº§å“å­˜åœ¨,å“ªæ€•å›¾ç‰‡é“¾æ¥ä¸ä¸€æ ·ä¹Ÿè¦ç§»é™¤),å¯èƒ½ä¼šè¯¯ä¼¤è®¸å¤šäº§å“æ•°æ®(ä½†æ˜¯è¿™ç§äº§å“ç›¸ä¼¼åº¦åº¦é«˜,æ•ˆæœå¯èƒ½ä¸å¥½ä¸€èˆ¬ä¹Ÿä¸å»ºè®®ä¿ç•™)
                (å¦‚æœä¸ºFalse,åˆ™åªå½“äº§å“åå’Œå›¾ç‰‡é“¾æ¥åŒæ—¶é‡å¤æ‰å»é‡,ä¼šä¿ç•™æ›´å¤šæ•°æ®,ä½†æ˜¯å¯¹äºè·¨ç«™äº§å“é‡å¤çš„æƒ…å†µæ— æ³•è‰¯å¥½å¤„ç†)
        """
        unique_rows = []
        dd = defaultdict(dict)  # è®¿é—®ddçš„æŸä¸ªå°šä¸å­˜åœ¨çš„å±æ€§(key)æ—¶,ä¼šè¿”å›ä¸€ä¸ªdict

        name_field = DBProductFields.NAME.value
        img_field = DBProductFields.IMAGES.value

        for i, row in enumerate(rows):
            product_name = row[name_field]
            product_img = row[img_field]
            # product_info = f"{{name:{product_name};sku:{product_sku}}}"
            # names_dict = dd.get(product_img, {})
            # names=dd[product_img]
            product_img_dict = dd[product_name]

            # è¿›åº¦è®¡æ•°å™¨
            with cnt_lock:
                self.progress += 1
                debug("progress: {{%s}}", self.progress)
                # print(f"progress: {self.progress}")
                # æ£€æŸ¥é‡å¤

            # è·å–å¤„ç†è¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯
            # æ•°æ®åº“æ–‡ä»¶æ‰€åœ¨çˆ¶ç›®å½•çš„ç¼–å·åç§°
            dbp = Path(db_path)
            db_id = dbp.parent.name
            # å»é‡ç­–ç•¥
            if (strict_mode and product_img_dict) or (product_img in product_img_dict):
                self.duplicate_warning(i, row, db_id)
                continue
            # if strict_mode and product_img_dict:
            #     self.duplicate_warning(i, row, db_id)
            #     continue
            # if product_img in product_img_dict:
            #     self.duplicate_warning(i, row, db_id)
            #     continue
            else:
                # å½“å‰äº§å“å°šæœªç»Ÿè®¡è¿‡,æ›´æ–°ç»Ÿè®¡è®¡æ•°å™¨
                unique_rows.append(row)
                info(
                    "keep:product:[%s] of [%s db]: duplicated name, \
but different image, keep records [%s]",
                    i,
                    db_id,
                    (row[name_field], row[img_field]),
                )

            # dd[product_img][product_name] = dd[product_img].get(product_name, 0) + 1
            dd[product_name][product_img] = dd[product_name].get(product_img, 0) + 1
        return unique_rows

    def duplicate_warning(self, i, row, db_id):
        """æ˜¾ç¤ºé‡å¤äº§å“è­¦å‘Š"""
        warning(
            "Jump:product:[%s] of [%s db]: duplicated product, skip this record [%s]!",
            i,
            db_id,
            (row[DBProductFields.NAME.value], row[DBProductFields.IMAGES.value]),
        )

    def get_data_from_db(self, db_path, fields):
        """ä»å•ä¸ªæ•°æ®åº“è·å–æŒ‡å®šå­—æ®µçš„å…¨éƒ¨æ•°æ®

        è­¦å‘Š:æ­¤å‡½æ•°åŠå…¶ä¾èµ–æœªåšæœ‰æ•ˆçš„è¶…å¤§æ•°æ®åº“ä¼˜åŒ–,å¯¹äºå‡ åä¸ªGBçš„sqliteæ–‡ä»¶,å¤„ç†å¯èƒ½å¡é¡¿ç”šè‡³å¾—ä¸åˆ°æœ‰æ•ˆå“åº”
        å¯¹äºè¶…å¤§æ•°æ®åº“,æš‚æ—¶ä¸èƒ½ç›´æ¥ç”¨æ­¤æ–¹æ³•å¤„ç†,éœ€è¦é¢å¤–çš„ä¼˜åŒ–
        (é€šå¸¸éœ€è¦é‡‡é›†ç¯èŠ‚æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ å‡ä¸å¿…è¦çš„å­—æ®µ,é€šå¸¸å¯ä»¥æœ‰æ•ˆé™ä½dbæ–‡ä»¶å¤§å°,ä½¿å…¶èƒ½å¤Ÿå¤„ç†)

        :param db_path: sqliteæ–‡ä»¶è·¯å¾„
        :param fields: éœ€è¦æŸ¥è¯¢çš„å­—æ®µåˆ—è¡¨æˆ–å­—ç¬¦ä¸²
        :return: ç»“æœåˆ—è¡¨
        """
        with sqlite3.connect(str(db_path)) as conn:
            # è®¾ç½®SQLiteæ€§èƒ½ä¼˜åŒ–å‚æ•°
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute("PRAGMA synchronous=OFF")
            conn.execute("PRAGMA cache_size=-10000")  # 10MBç¼“å­˜
            conn.row_factory = sqlite3.Row
            rows = self.get_selected_fields(
                connection=conn, table=DEFAULT_TABLE, fields=fields, empty_check=True
            )
        conn.close()
        return rows

    def get_data_from_dbs(
        self, dbs, max_workers=8, fields="", strict_mode=False, count_rows_only=False
    ):
        """
        ä½¿ç”¨å¤šçº¿ç¨‹ä»å¤šä¸ªSQLiteæ•°æ®åº“å¹¶è¡Œè¯»å–æ•°æ®

        Args:
            dbs: SQLiteæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            max_workers: æœ€å¤§çº¿ç¨‹æ•°
            fields: éœ€è¦æŸ¥è¯¢çš„å­—æ®µåˆ—è¡¨æˆ–å­—ç¬¦ä¸²
            query: SQLæŸ¥è¯¢è¯­å¥
            max_workers: æœ€å¤§çº¿ç¨‹æ•°
            strict_mode: æ˜¯å¦ä»…æ¯”è¾ƒäº§å“å,åŒåäº§å“å°†è¢«ç§»é™¤åªä¿ç•™ä¸€ä¸ª
            count_rows_only: æ˜¯å¦åªè¿”å›è¡Œæ•°,ä¸è¿”å›æ•°æ®,ç”¨äºå¿«é€Ÿç»Ÿè®¡é‡‡é›†çš„æ•°æ®æœ‰å¤šå°‘

        Returns:
            list: åˆå¹¶åçš„æ•°æ®åˆ—è¡¨
        """

        all_data = self.db_rows
        info("read data from %s files using %s threads...", len(dbs), max_workers)
        batch_size = 10  # æ¯æ‰¹å¤„ç†10ä¸ªæ–‡ä»¶
        for i in range(0, len(dbs), batch_size):
            batch = dbs[i : i + batch_size]
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(
                        self.get_data_init,
                        db_file,
                        fields=fields,
                        strict_mode=strict_mode,
                        count_rows_only=count_rows_only,
                    )
                    for db_file in batch
                ]
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                result = future.result()
                if result:
                    all_data.extend(result)

        return all_data

    def remove_sensitive_info_from_description(self, dbs):
        """
        ç§»é™¤æè¿°ä¸­çš„æ•æ„Ÿä¿¡æ¯
        """
        rows = self.get_data(dbs=dbs)
        for row in rows:
            description = row[DBProductFields.DESCRIPTION.value]
            row[DBProductFields.DESCRIPTION.value] = remove_sensitive_info(description)
            # ç§»é™¤è¿‡å¤šé‡å¤çš„é—®å·
            # row[DBProductFields.DESCRIPTION.value] = re.sub(rf"\?{3,}", " ", description)

        return rows

    def update_products(
        self, dbs, process_attribute=False, sku_suffix=None, strict_mode=False
    ):
        """
        æ›´æ–°äº§å“æ•°æ®,è®©æ•°æ®æ›´åŠ è§„èŒƒ(åŒ…æ‹¬äº§å“æè¿°æ¸…ç†ç­‰)

        åœ¨ä»sqlite(db3)æ–‡ä»¶è¯»å–æ•°æ®,è°ƒç”¨get_data()çš„è¿‡ç¨‹ä¸­å·²ç»åšäº†åˆæ­¥çš„æ•°æ®å¤„ç†
        (æ¯”å¦‚ä»·æ ¼å¤„ç†,å»é™¤é‡å¤äº§å“ç­‰,è¿™äº›æ˜¯å›¢é˜Ÿä¸šåŠ¡å¿…é¡»çš„)

        è€Œä¸‹é¢çš„æ­¥éª¤æ˜¯è®©æ•°æ®æ›´åŠ è§„èŒƒ(å¦‚æœä¸å¤„ç†,ä¸ä¸€å®šä¼šå‡ºç°é—®é¢˜)
        - ç»Ÿä¸€ç¼–å·(number)æ•°æ®åº“ä¸­äº§å“å‹å·
        - (å°½é‡)æ¸…ç†æè¿°ä¸­ä¸éœ€è¦çš„å†…å®¹,å¦‚é‚®ç®±åœ°å€ã€ç½‘å€ã€ç”µè¯å·ç ç­‰,
            å¹¶ä¸”ï¼Œå¯¹äºåº“å­˜è¿™ç±»æ¶ˆæ¯,éœ€è¦é‡‡é›†å‘˜é‡‡é›†æ—¶é¿å…é‡‡é›†åˆ°æˆ–è€…åŠæ—¶æ›¿æ¢ä¸ºç©ºç¿»è¯‘åé˜…è¯»æ£€æŸ¥
        - å¤„ç†ä¸è§„èŒƒçš„å±æ€§å€¼(å»ºè®®é‡‡é›†å‘˜åœ¨é‡‡é›†æ—¶å°±è®¤çœŸæŠ½æŸ¥,æ¯•ç«Ÿäº‹åæŸ¥å‡ºé—®é¢˜å†è¡¥æ•‘å¯èƒ½æ›´æµªè´¹æ—¶é—´)

        :param process_attribute: æ˜¯å¦å¤„ç†å±æ€§å€¼,é»˜è®¤ä¸ºFalse(å»ºè®®æ‰‹åŠ¨è°ƒç”¨ç›¸å…³æ–¹æ³•æ£€æŸ¥å±æ€§å€¼å,
            å¦‚æœæ²¡æœ‰å¤ªå¤šä¸è§„èŒƒæˆ–è€…æ— å…³ç´§è¦æ‰è®¾ç½®ä¸ºTrue)
        :param strict_mode: æ˜¯å¦ä¸¥æ ¼æ¨¡å¼(æ£€æŸ¥äº§å“æè¿°ä¸­çš„æ•æ„Ÿä¿¡æ¯),é»˜è®¤ä¸ºFalse(å¯ä»¥åŠ é€Ÿå¯¼å‡º,æ•ˆæœä¸å¥½ä¼°è®¡,ä½†æ˜¯æ•°æ®å¯èƒ½åŒ…å«é‚®ç®±æˆ–è€…url)


        """

        # è°ƒç”¨number_skuæ–¹æ³•ç»Ÿä¸€äº§å“ç¼–å·
        self.number_sku(dbs=dbs, sku_suffix=sku_suffix)
        # å¦‚æœprocess_attributeä¸ºTrueï¼Œåˆ™å¤„ç†å±æ€§å€¼
        if process_attribute:
            self.empty_invalid_attribute_subset(dbs=dbs)
        info("Jump process: remove sensitive info from description.")
        # å¦‚æœstrict_modeä¸ºTrueï¼Œåˆ™ä¸¥æ ¼æ¨¡å¼å¤„ç†ï¼Œç§»é™¤æè¿°ä¸­çš„æ•æ„Ÿä¿¡æ¯
        if strict_mode:
            # warning("Warning: strict mode is on, remove sensitive info from description.")
            self.remove_sensitive_info_from_description(dbs=dbs)

        return self.db_rows

    def number_sku(self, dbs, sku_suffix=None, strict_mode=False):
        """
        ç»Ÿä¸€ç¼–å·(number)æ•°æ®åº“ä¸­äº§å“å‹å·
        ç»è¿‡å¿…è¦æ•°æ®ç­›é€‰(å»é‡å’Œè¶…ä½ä»·è¿‡æ»¤å),ç¼–åˆ¶ç»Ÿä¸€çš„äº§å“ä»·æ ¼
        """
        if sku_suffix is None:
            sku_suffix = self.language

        rows = self.get_data(dbs=dbs, strict_mode=strict_mode)
        sku = DBProductFields.SKU.value
        for idx, _ in enumerate(iterable=rows):
            new_sku = f"SK{idx + 1:07d}-{sku_suffix}"
            debug("SKU: %s-> %s", rows[idx].get(sku, ""), new_sku)
            rows[idx][sku] = new_sku

    def get_data(
        self, dbs, get_dict_row=True, strict_mode=False, count_rows_only=False
    ):
        """ä»ç¼“å­˜æˆ–æ•°æ®åº“ä¸­è·å–æ•°æ®
        å¦‚æœç¼“å­˜ä¸­ä¸Šä¸å­˜åœ¨æ•°æ®,åˆ™ä»æ•°æ®åº“ä¸­è¯»å–æ•°æ®å¹¶ç¼“å­˜åˆ°self.data_rowsä¸­

        Args:
            dbs: SQLiteæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            get_dict_row: æ˜¯å¦è¿”å›å­—å…¸å½¢å¼çš„è¡Œ,é»˜è®¤ä¸ºTrue
            strict_mode: æ˜¯å¦ä»…æ¯”ä»·äº§å“å,åŒåäº§å“å°†è¢«ç§»é™¤åªä¿ç•™ä¸€ä¸ª
            count_rows_only: æ˜¯å¦åªè¿”å›è¡Œæ•°,ä¸è¿”å›æ•°æ®,ç”¨äºå¿«é€Ÿç»Ÿè®¡é‡‡é›†çš„æ•°æ®æœ‰å¤šå°‘

        """

        if not self.db_rows:
            self.db_rows = self.get_data_from_dbs(
                dbs=dbs, strict_mode=strict_mode, count_rows_only=count_rows_only
            )
        if get_dict_row:
            self.db_rows = [dict(db_row) for db_row in self.db_rows]

        if count_rows_only:
            reports = self.db_reports
            cnt = 0
            for v in reports.values():
                cnt += v["total_raw"]
            print(f"total rows: {cnt}")
            info("total rows: %s", cnt)
            info(str(self.db_reports))
            sys.exit(0)  # åªç»Ÿè®¡è¡Œæ•°,ä¸åšæ•°æ®å¤„ç†,ç«‹å³é€€å‡ºç¨‹åº(0è¡¨ç¤ºæ­£å¸¸é€€å‡º)
        return self.db_rows

    def get_products_with_attribute_values(self, dbs):
        """
        è·å–æ‰€æœ‰äº§å“çš„å±æ€§å€¼
        """
        rows = self.get_data(dbs=dbs)
        for row in rows:
            if row[DBProductFields.ATTRIBUTE_VALUES.value]:
                self.products_with_attribute.append(row)

        return self.products_with_attribute

    def get_attribute_of_products(
        self,
        dbs,
        check_invalid_attribute_subset=True,
        check_invalid_attribute_supperset=False,
    ):
        """
        è·å–æ‰€æœ‰å…·æœ‰å±æ€§å€¼çš„äº§å“çš„å­—æ®µç®€åŒ–çš„å­—å…¸åˆ—è¡¨
        1. name
        2. sku
        3. attribute_values
        4. page_url
        æ”¯æŒé€šè¿‡å¼€å…³å‚æ•°æ‰§è¡Œä¸è§„èŒƒå±æ€§å€¼æ•°æ®åˆ†ç±»
        åé¢ä¸¤ä¸ªå‚æ•°åœ¨å¤§é‡ä¸è§„èŒƒçš„å±æ€§å€¼æ•°æ®æ—¶,å¯èƒ½ä¼šå¯¼è‡´å¯¼å‡ºç¼“æ…¢,å ç”¨cpuèµ„æº
        (è™½ç„¶è®¾ç½®äº†å¼€å…³,ä¸»è¦ç”¨äºæµ‹è¯•å’Œç¡®è®¤å¯¼å‡ºé€Ÿåº¦çš„ç“¶é¢ˆ,æé†’è¯»è€…æ£€æŸ¥é‡‡é›†æ•°æ®æ˜¯å¦æœ‰é‡å¤§é—®é¢˜)


        :param dbs: SQLiteæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        :param check_invalid_attribute_subset: æ˜¯å¦æ£€æŸ¥ä¸è§„èŒƒçš„å±æ€§å€¼å­é›†(å±æ€§å€¼ä¸­åŒ…å«#å·);
            å¯¹äºåŒ…å«å¤§é‡ä¸è§„èŒƒå±æ€§å€¼çš„æ•°æ®å¯èƒ½å¯¼è‡´å¯¼å‡ºç¼“æ…¢,å ç”¨cpuèµ„æº
        :param check_invalid_attribute_supperset: æ˜¯å¦æ£€æŸ¥ä¸è§„èŒƒçš„å±æ€§å€¼è¶…é›†(å±æ€§å€¼ä¸­åŒ…å«#å·å’Œ|å·)
            å¯¹äºåŒ…å«å¤§é‡ä¸è§„èŒƒå±æ€§å€¼çš„æ•°æ®å¯èƒ½å¯¼è‡´å¯¼å‡ºç¼“æ…¢,å ç”¨cpuèµ„æº


        """
        rows_with_attribute = self.get_products_with_attribute_values(dbs=dbs)
        for row in rows_with_attribute:
            name = row[DBProductFields.NAME.value]
            # sku: str = row[DBProductFields.SKU.value]
            sku = row.get(DBProductFields.SKU.value, "")
            attribute_values = row[DBProductFields.ATTRIBUTE_VALUES.value]
            page_url = row[DBProductFields.PAGE_URL.value]
            item = {
                DBProductFields.NAME.value: name,
                DBProductFields.SKU.value: sku,
                DBProductFields.ATTRIBUTE_VALUES.value: attribute_values,
                DBProductFields.PAGE_URL.value: page_url,
            }
            self.attribute_checker.append(item)
            # å¯é€‰çš„,æ ¹æ®å‚æ•°å¼€å…³æ˜¯å¦æ‰§è¡Œä¸‹é¢çš„åˆ†ç±»ç»Ÿè®¡ä»£ç 
            # ä¸‹é¢çš„ä¸¤ä¸ªæ’å…¥è¯­å¥æœ‰ä¸¤ç§é€‰æ‹©:æ’å…¥itemæˆ–è€…row
            row = item
            if check_invalid_attribute_subset:
                self._check_invalid_attribute_subset(row)
            if check_invalid_attribute_supperset:
                self._check_invalid_attribute_supperset(row)
        return self.attribute_checker

    def empty_invalid_attribute_subset(self, dbs, remove=False):
        """ç§»é™¤æ˜¾ç„¶ä¸åˆè§„èŒƒçš„å±æ€§å€¼

        :param remove: æ˜¯å¦ç§»é™¤äº§å“,è€Œä¸ä»…ä»…æ˜¯å°†å±æ€§å€¼ç½®ç©º,é»˜è®¤ä¸ºFalse,ä»…ç½®ç©º

        :return: å¤„ç†åçš„æ•°æ®åº“è¡Œåˆ—è¡¨

        é‡‡ç”¨åˆé€‚çš„æ–¹å¼æ‰¹é‡ç½®ç©ºæˆ–ç§»é™¤åˆ—è¡¨ä¸­çš„å…ƒç´ 
        """
        # for row in self.invalid_attribute_subset:
        #     self.db_rows.remove(row)
        self.get_attribute_of_products(dbs=dbs)
        # æ„é€ ä»¥äº§å“sku_i:name_iä¸ºkey-valueçš„å­—å…¸,ä¾¿äºé€ŸæŸ¥
        sku_field = DBProductFields.SKU.value
        name_field = DBProductFields.NAME.value
        attribute_field = DBProductFields.ATTRIBUTE_VALUES.value
        # åŸºäºself.invalid_attribute_subsetå¡«å……å­—å…¸
        invalid_dict = self.invalid_index_dict
        for item in self.invalid_attribute_subset:
            invalid_dict[item[sku_field]] = f"[{item[name_field]}]"

        # éå†æ•°æ®åº“è¡Œ,å¤„ç†æ˜¾ç„¶ä¸åˆè§„èŒƒçš„å±æ€§å€¼(è¿è¡Œå¯èƒ½æŠ¥é”™,ç­‰å¾…ä¿®å¤ TODO)
        if remove:
            # ç§»é™¤ä¸è§„èŒƒå±æ€§å€¼çš„äº§å“
            # æ–¹æ¡ˆ1:ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼åˆ›å»ºæ–°åˆ—è¡¨
            self.db_rows = [
                row for row in self.db_rows if row[sku_field] not in invalid_dict
            ]

            # æ–¹æ¡ˆ2:ä½¿ç”¨åˆ—è¡¨çš„removeæ–¹æ³•(åŸåœ°æ›¿æ¢)
            # to_remove = [row for row in self.db_rows if row[sku] in invalid_dict]
            # for row in to_remove:
            #     self.db_rows.remove(row)
        else:
            # ä»…å°†ä¸è§„èŒƒå±æ€§å€¼çš„äº§å“ç½®ç©º
            # æ–¹æ¡ˆ1:ç›´æ¥æ“ä½œself.db_rowsä¸­çš„å…ƒç´ (æ›´ç¨³,ä½†æ˜¯é€Ÿåº¦æ›´æ…¢)
            # for row in self.db_rows:
            #     sku=row[sku_field]
            #     if invalid_dict[sku]:
            #         row[attribute_field] = ""
            # æ–¹æ¡ˆ2:é€šè¿‡self.invalid_attribute_subsetçš„éå†ä¿®æ”¹(é€Ÿåº¦å¿«)
            for item in self.invalid_attribute_subset:
                # sku = item[sku_field]
                item[attribute_field] = ""

        return self.db_rows

    def _check_invalid_attribute_subset(self, row):
        """åˆ¤æ–­å±æ€§å€¼æ˜¯å¦æœ‰æ•ˆ

        åˆæ³•çš„å±æ€§å€¼çš„ä¸€èˆ¬æ ¼å¼:attr1#value1|value2|...~attr2#value1|value2|...
        å…¶ä¸­attr1,attr2ä¸ºå±æ€§åç§°,value1,value2ä¸ºå±æ€§å€¼,~ä¸ºå„ç»„å±æ€§å€¼åˆ†éš”ç¬¦

        ç®€å•æœŸé—´,è¿™é‡Œä»…æ£€æŸ¥å±æ€§å€¼æ˜¯å¦æ»¡è¶³æ­£åˆ™: .*#.*

        :param row: è¦è¢«æ£€æŸ¥çš„æ•°æ®åº“è¡Œ

        """
        value = row[DBProductFields.ATTRIBUTE_VALUES.value]
        p = re.compile(r".*#.*")
        if value and not p.match(value):
            debug("Invalid attribute value: %s", value)
            self.invalid_attribute_subset.append(row)
        return self.invalid_attribute_subset

    def _check_invalid_attribute_supperset(self, row):
        """ä¸¥æ ¼çš„æ–¹å¼åˆ¤æ–­å±æ€§å€¼æ˜¯å¦æœ‰æ•ˆ
        æ£€æŸ¥ç»“æœåˆ—å‡ºçš„æ•°æ®è¡Œä¸ä¸€å®šæ˜¯æ— æ•ˆçš„,åªæ˜¯ä¾›å‚è€ƒ,æ£€æŸ¥å¯ç–‘çš„å¸¦æœ‰å±æ€§å€¼çš„è¡Œ,å°¤å…¶æ˜¯æ–°æ‰‹,è€æ‰‹å¯ä»¥è·³è¿‡æ£€æŸ¥

        è¿™é‡Œæ£€æŸ¥å±æ€§å€¼æ˜¯å¦åŒæ—¶å…·æœ‰#å’Œ|

        :param row: è¦è¢«æ£€æŸ¥çš„æ•°æ®åº“è¡Œ

        """
        value = row[DBProductFields.ATTRIBUTE_VALUES.value]
        name = row[DBProductFields.NAME.value]
        sku = row[DBProductFields.SKU.value]
        p = re.compile(r".*#.*\|.*")
        if value and not p.match(value):
            warning(
                "atypical or non-standard  attribute value: {name=%s;sku=%s;value=%s}",
                name,
                sku,
                value,
            )
            self.invalid_attribute_supperset.append(row)
        return self.invalid_attribute_supperset

    def update_hotsale(
        self,
        row,
        cat_field=CSVProductFields.CATEGORIES.name,
        # hot_sale_category="",
        hot_class=LanguagesHotSale,
        language="",
    ):
        """è®¾ç½®"çƒ­é”€"è¿™é‡Œäº§å“åˆ†ç±»åç§°

        :param row: æ•°æ®åº“è¡Œ
        :param lang: è¯­è¨€ä»£ç ,é»˜è®¤ä¸ºUS
        :return: è®¾ç½®åçš„åˆ†ç±»åç§°
        """
        language = language or self.language
        # if not hot_sale_category:
        hot_sale_category = hot_class.get_one_hot_sale_names(language=language)
        row[cat_field] = hot_sale_category

        debug("change:category [%s]->[%s]  ", row[cat_field], hot_sale_category)

        return hot_sale_category

    def get_lines_lst(self, dbs):
        """
        å°†è¯»å–åˆ°çš„æ•°æ®åº“è¡Œè½¬æ¢ä¸ºåˆ—è¡¨è¿”å›
        """
        res = self.get_data(dbs=dbs)
        lines = []
        for r in res:
            lst = [r[v] for v in self.field_values_full]
            lines.append(lst)
        return lines

    def _get_lines_dict_raw(self, dbs, extra_fields=None) -> list[dict]:
        """
        è·å–æ‰€æœ‰äº§å“æ•°æ®ï¼Œæ¯è¡Œä½œä¸ºå­—å…¸è¿”å›,ä¸€èˆ¬ä¸ç›´æ¥è°ƒç”¨
        é”®ä½¿ç”¨ProductFieldæšä¸¾æˆå‘˜,å­—æ®µä»…åŒ…å«æ ¸å¿ƒçš„å­—æ®µ,å¯ä»¥ä¾›å¦ä¸€ä¸ªæ–¹æ³•è°ƒç”¨:get_lines_dict_full
        å®ƒå…è®¸ä½ è‡ªå®šä¹‰æ·»åŠ å­—å…¸,ä¾¿äºåæœŸå¯¼å‡ºä¸ºwoocommerceè¦æ±‚çš„csvæ–‡ä»¶

        æ­¤æ–¹æ³•å…è®¸ä½ å¯é€‰åœ°åŠ å…¥é¢å¤–çš„é”®å€¼å¯¹

        :param extra_fields: å¯é€‰å‚æ•°ï¼ŒåŒ…å«é¢å¤–é”®å€¼å¯¹çš„å­—å…¸(è¿˜å¯ä»¥æ˜¯å…¶ä»–å½¢å¼çš„é”®å€¼å¯¹,æ¯”å¦‚å…ƒç»„ç­‰)
        :return: å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸é”®æ˜¯ProductFieldæšä¸¾æˆå‘˜å’Œextra_fieldsä¸­çš„é”®ï¼Œ
                å€¼æ˜¯å¯¹åº”çš„æ•°æ®åº“å€¼å’Œextra_fieldsä¸­çš„å€¼
        è¿”å›çš„åˆ—è¡¨ä¸­çš„å…ƒç´ ä¾‹å­
        {
            'NAME': 'Stabilimento balneare "VICTORIA" Piccolo',
            'CATEGORIES': 'Miglior valore',
            'REGULAR_PRICE': '7.50',
            'IMAGES': 'http://birdshopchristina.com/cdn/shop/files/bagnetto-dipinto.jpg',
            'ATTRIBUTE_VALUES': '',
            'TAGS': 'STA',
            'SKU': 'SK0000002-IT',
            'DESCRIPTION': "<p>...</p>",
            'PAGE_URL': 'https://it.birdshopchristina.com/de/products/naamloos-10sep-_21-36'
        }
        """
        rows = self.get_data(dbs=dbs)
        lines = []
        for row in rows:
            line_dict = {}
            for field in DBProductFields:
                line_dict[field.name] = row[field.value]  # ä½¿ç”¨æšä¸¾æˆå‘˜ä½œä¸ºé”®
            if extra_fields is not None:
                line_dict.update(extra_fields)  # åˆå¹¶é¢å¤–çš„é”®å€¼å¯¹
            lines.append(line_dict)
        return lines

    def get_sale_price_yy(self, price, limit_sale=169.99):
        """ä¸´æ—¶çš„æ–°ä»·æ ¼å¤„ç†æ–¹æ¡ˆ
        1.åŸä»·*0.5,å¦‚æœæŠ˜åä»ç„¶é«˜äº169,åˆ™é™åˆ¶ä¸º169

        """
        try:
            price = float(price)
        except ValueError:
            msg = f"price [{price}] is not a float"
            error(msg)
        sale_price = price * 0.5
        if sale_price > limit_sale:
            sale_price = limit_sale
        # ä¿ç•™2ä½å°æ•°
        sale_price = round(sale_price, 2)
        return sale_price

    def get_sale_price(self, price, limit_sale=298.98):
        """è·å–äº§å“æŠ˜æ‰£ä»·æ ¼
        1.ä»·æ ¼å°äº100çš„æ‰“3æŠ˜
        2.ä»·æ ¼100åˆ°300çš„æ‰“0.25æŠ˜
        3.ä»·æ ¼å¤§äº300çš„å…ˆæ‰“0.2æŠ˜
        4.ä»·æ ¼å¤§äº300çš„æ‰“å®Œ0.2æŠ˜åã€‚ä»·æ ¼è¿˜å¤§äº300çš„ä»·æ ¼è®¾ç½®ä¸ºä¸Šé™å€¼
        :param row: æ•°æ®åº“è¡Œ
        :return: æŠ˜æ‰£ä»·æ ¼(å¦‚æœè¿”å›0,è¡¨ç¤ºè¿™ä¸ªäº§å“åˆå§‹ä»·æ ¼è¿‡äºä½æˆ–è¿‡é«˜,è¿™ä¸ªäº§å“è¦è¿‡æ»¤æ‰,ç”±è°ƒç”¨è€…å¤„ç†)
        """
        lowest_price = self.lowest_price
        highest_price = self.highest_price
        try:
            price = float(price)
        except ValueError:
            msg = f"price [{price}] is not a float"
            error(msg)
            return 0
        except Exception as e:
            msg = f"price [{price}] is not a float,{e}"
            error(msg)
            return 0
        # ç§»é™¤è¿‡ä½æˆ–è¿‡é«˜ä»·äº§å“
        if price > highest_price:
            return 0
        if price < lowest_price:
            return 0
        # æ™®é€šæƒ…å†µ
        sale_price = 0
        if price < 100:
            sale_price = price * 0.3
        elif price >= 100 and price < 300:
            sale_price = price * 0.25
        elif price >= limit_sale:
            sale_price = price * 0.2
            if sale_price >= limit_sale:
                sale_price = limit_sale

        # ä¿ç•™2ä½å°æ•°
        sale_price = round(sale_price, 2)
        return sale_price

    def get_lines_dict_for_csv(
        self,
        dbs,
        img_mode=ImageMode.NAME_AS_URL,
        extra_fields=None,
        hot_class=LanguagesHotSale,
        language="",
        limit_sale=298.98,
        req_response=False,
        default_extension=".webp",
    ):
        """
        è·å–äº§å“æ•°æ®è¡Œçš„å­—æ®µè¡¥å……å’Œä¿®æ”¹åçš„å­—å…¸å½¢å¼æ•°æ®ï¼Œæ¯è¡Œæ•°æ®ä½œä¸ºå­—å…¸è¿”å›,æœåŠ¡äºå¯¼å‡ºåˆ°csvçš„é˜¶æ®µé¢„å¤‡
        (å­—æ®µæ•°é‡è¶³å¤Ÿ,ä½†æ˜¯å­—æ®µåå­—è¿˜ä¸æ˜¯woocommerceè¦æ±‚çš„,æ¯”å¦‚æš‚æ—¶äº§å“åå­—,è¿˜æ˜¯NAME,è€Œä¸æ˜¯Name,åé¢ç»Ÿä¸€è½¬æ¢)

        æ“ä½œçš„å¯¹è±¡(å­—å…¸)çš„keyæ˜¯æšä¸¾å€¼ä¸­çš„æˆå‘˜nameåå­—(å¤§å†™è‹±æ–‡),è€Œä¸æ˜¯value(å¤„äºDB->CSVçš„ä¸­é—´çŠ¶æ€)
        æ­¤æ–¹æ³•ä¼šåŸºäºåŸå§‹é‡‡é›†çš„æ•°æ®åº“ä¸­çš„å­—æ®µçš„åŸºç¡€ä¸Šå¢åŠ ä¸€äº›å­—æ®µ,åˆ©ç”¨å­—å…¸çš„å·¦å€¼çš„æ–¹å¼æ·»åŠ å­—æ®µå’Œèµ‹å€¼,ä¾‹å¦‚
        row[CSVProductFields.SALE_PRICE.name] = sale_price
        row[CSVProductFields.ATTRIBUTE_NAME.name] = ""

        åŒ…å«ä¸šåŠ¡æ‰€éœ€è¦çš„æ‰€æœ‰å­—æ®µ,æˆ–è€…é¢å¤–éœ€è¦çš„å­—æ®µ,ä½†æ˜¯è¡¨å¤´åè¿˜ä¸æ˜¯woocommerceè¦æ±‚çš„
        éœ€è¦è°ƒç”¨å…¶ä»–æ–¹æ³•,æ­¤æ–¹æ³•è¾…åŠ©export_csvæ–¹æ³•å¯¼å‡ºwoocommerceè¦æ±‚çš„csvæ–‡ä»¶

        :param extra_fields: å¯é€‰å‚æ•°ï¼ŒåŒ…å«é¢å¤–é”®å€¼å¯¹çš„å­—å…¸(è¿˜å¯ä»¥æ˜¯å…¶ä»–å½¢å¼çš„é”®å€¼å¯¹,æ¯”å¦‚å…ƒç»„ç­‰)
        :param lang: è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸º"US"
        :param img_mode: å›¾ç‰‡å¤„ç†æ¨¡å¼,é»˜è®¤ä¸ºImageMode.NAME_AS_URL,å³å›¾ç‰‡é“¾æ¥ç›´æ¥ä½œä¸ºå›¾ç‰‡å
        :param hot_class: çƒ­é”€åˆ†ç±»ç±»,é»˜è®¤ä¸ºLanguagesHotSale,å³è¯­è¨€çƒ­é”€è¯
        :param req_response: å¦‚æœç›´æ¥ä»responseä¸­è·å–æ–‡ä»¶ç±»å‹å¤±è´¥ï¼Œæ˜¯å¦éœ€è¦é’ˆå¯¹urlå‘èµ·ç½‘ç»œè¯·æ±‚è·å–å“åº”æ¥è®¡ç®—æ–‡ä»¶ç±»å‹

        :return: list[dict] è¿”å›å­—æ®µæ‰©å……åçš„æ•°æ®è¡Œçš„åˆ—è¡¨
        """
        language = language or self.language
        rows = self._get_lines_dict_raw(dbs=dbs, extra_fields=extra_fields)
        expanded_rows = []
        # print(f"[{default_extension}]ğŸ")
        for row in rows:
            # æ•°æ®å¤„ç†:ç‰¹ä»·
            price = row[DBProductFields.REGULAR_PRICE.name]
            if self.yy:
                sale_price = self.get_sale_price_yy(price, limit_sale=limit_sale)
            else:
                sale_price = self.get_sale_price(price, limit_sale=limit_sale)
            if sale_price == 0:
                continue
            # æ•°æ®å¤„ç†:äº§å“åˆ†ç±»(å°†åˆ†ç±»å–å€¼ä¸ºéå¸¸è§„å€¼åšä¸€ä¸ªæ°å½“çš„è½¬æ¢,æ¯”å¦‚çƒ­é”€è¿™ç±»çš„æ­¤)
            category = row[CSVProductFields.CATEGORIES.name]
            if self.is_need_update_category(category):
                self.update_hotsale(row=row, hot_class=hot_class, language=language)
            # å°†è®¡ç®—åˆ°çš„ä»·æ ¼æ•°æ®å†™å…¥åˆ°å¯¹åº”çš„å­—å…¸(ä¸å­˜åœ¨æŒ‡å®šå­—æ®µæ—¶ä¼šåˆ›å»º,å³æ•°æ®è¡Œrowå­—å…¸å¯¹è±¡ä¸­å†™å…¥å¯¹åº”key:value)
            row[CSVProductFields.SALE_PRICE.name] = sale_price
            # æ‰©å……ä¸€ä¸ªç©ºå€¼å±æ€§å€¼å­—æ®µ,ç”¨äºåæœŸå±æ€§å€¼å¤„ç†
            row[CSVProductFields.ATTRIBUTE_NAME.name] = ""

            # ä¸ºå±æ€§å€¼éç©ºçš„äº§å“æ·»åŠ é»˜è®¤å±æ€§å(mycustom)
            if row[CSVProductFields.ATTRIBUTE_VALUES.name]:
                # if row.get(CSVProductFields.ATTRIBUTE_VALUES.value):
                row[CSVProductFields.ATTRIBUTE_NAME.name] = "mycustom"
            # å¤„ç†å›¾ç‰‡(å›¾ç‰‡é“¾æ¥)å­—æ®µ
            img_field = CSVProductFields.IMAGES.name
            img_url_field = CSVProductFields.IMAGES_URL.name
            sku_field = CSVProductFields.SKU.name
            # æ ¹æ®å›¾ç‰‡æ¨¡å¼æ‰§è¡Œå¯¹åº”çš„å­—æ®µæ‰©å……å’Œä¿®æ”¹
            if img_mode == ImageMode.NAME_AS_URL:
                # é»˜è®¤æ¨¡å¼,ä¸éœ€è¦ä¿®æ”¹
                pass
            else:
                # éœ€è¦è¿›è¡Œå›¾ç‰‡ç›¸å…³å­—æ®µçš„è¿ç§»
                # 1.è®¾ç½®å›¾é“¾å­—æ®µ(ç›´æ¥å¼•ç”¨åŸå›¾ç‰‡å­—æ®µ)
                ## ç”±äºé‡‡é›†å™¨æš‚æ—¶ä»…é‡‡é›†å›¾ç‰‡é“¾æ¥,å­˜æ”¾äº§å“å›¾ç‰‡å­˜æ”¾çš„å–å€¼èµ‹å€¼ç»™å›¾ç‰‡é“¾æ¥å­—æ®µ,æ‰€ä»¥ç›´æ¥å¼•ç”¨åŸå›¾ç‰‡å­—æ®µå³å¯
                img_urls = row[img_field]
                row[img_url_field] = img_urls
                if not img_urls:
                    error("Empty image url for row:", row)
                    img_urls = ""

                # 2.å¤„ç†å›¾åå­—æ®µ(è€ƒè™‘å¤šå›¾,ä»å›¾ç‰‡é“¾æ¥è§£æå…¥æ‰‹åˆ¤æ–­å›¾ç‰‡æ•°é‡ä»¥åŠå›¾ç‰‡åå–åå’Œç¼–å·)
                ## è€ƒè™‘åˆ°å¯èƒ½ä¼šé‡‡é›†å¤šä¸ªå›¾ç‰‡,è¿™é‡Œé¢„è®¾å›¾ç‰‡é“¾æ¥ä¹‹é—´çš„åˆ†éš”ç¬¦å¯èƒ½æ˜¯">"," ",ä¸ºäº†ä¾¿äºç»Ÿä¸€å¤„ç†,å°†">"æ›¿æ¢ä¸ºç©ºæ ¼,ç„¶ååˆ©ç”¨splitåˆ†å‰²
                # img_url_lst = img_urls.replace(">", " ").split()
                img_url_lst = split_urls(img_urls)
                img_names = []
                # ä»¥skuå‘½åå›¾ç‰‡ğŸˆ
                if img_mode == ImageMode.NAME_FROM_SKU:
                    sku = row[sku_field]
                    # åŸºäºsku,ç¼–å·å‘½åè¯¥äº§å“çš„å¤šä¸ªå›¾ç‰‡(å¦‚æœæœ‰å¤šå›¾çš„è¯)
                    img_names = [
                        complete_image_file_extension(
                            file=f"{sku}-{i}"
                            + fnh.get_image_extension_from_url_str(url=img_url).replace(
                                "%", "_"
                            ),
                            # + self._get_img_extension(
                            #     img_url=img_url,
                            #     req_response=req_response,
                            #     prefix_dot=True,
                            # ),
                            default_extension=default_extension,
                        )
                        for i, img_url in enumerate(img_url_lst)
                    ]
                elif img_mode == ImageMode.NAME_FROM_URL:
                    # ä»urlä¸­è·å–å›¾ç‰‡åç§°
                    img_names = [
                        complete_image_file_extension(
                            get_filebasename_from_url(img_url).replace("%", "_"),
                            default_extension=default_extension,
                        )
                        for img_url in img_url_lst
                    ]
                elif img_mode == ImageMode.NAME_MIX:
                    # æ··åˆskuå’Œæ—¶é—´æˆ³ä»¥åŠurlä¸­çš„å›¾ç‰‡åç§°
                    sku = row[sku_field]

                    # print(f"[{default_extension}]ğŸ")
                    img_names = [
                        complete_image_file_extension(
                            # å°†è¿‡é•¿çš„å›¾ç‰‡åæˆªæ–­é˜²æ­¢wordpressåŠ è½½å›¾ç‰‡å¤±è´¥ğŸˆ
                            # .replace('%','_')
                            file=f"{sku}-{i}-{self.stamp}-"
                            f"-{re.sub(r'[=:%?]', '_', get_filebasename_from_url(img_url))}"[
                                : self.max_img_name_length
                            ],
                            default_extension=default_extension,
                        )
                        for i, img_url in enumerate(img_url_lst)
                    ]

                row[img_field] = ",".join(img_names)
                if img_mode in [ImageMode.NAME_FROM_URL, ImageMode.NAME_MIX]:
                    # å°†å›¾ç‰‡åä¸­çš„ç¦è¯ç§»é™¤
                    img_field = CSVProductFields.IMAGES.name
                    row[img_field] = self.process_forbidden_words(row[img_field])
            # æ‰©å……æ•°æ®è¡Œå­—å…¸
            expanded_rows.append(row)
        return expanded_rows

    def _get_img_extension(self, img_url, req_response=False, prefix_dot=False):
        """
        å°è¯•è·å–å›¾ç‰‡æ–‡ä»¶çš„åç¼€å
        (å¤„ç†å•ä¸ªå›¾ç‰‡é“¾æ¥,å¯ä»¥é…åˆå¾ªç¯æ‰¹é‡å¤„ç†)
        :param img_url: å›¾ç‰‡é“¾æ¥
        :return: å›¾ç‰‡åç¼€å
        """
        # if not img_url:
        #     return ""
        # return img_url.split(".")[-1]

        res = fnh.get_file_extension(
            url=img_url, req_response=req_response, prefix_dot=prefix_dot
        )
        return res

    def split_list_average(self, lst, n):
        """å°½å¯èƒ½å‡åŒ€çš„å°†lståˆ‡åˆ†ä¸ºnä»½
        è¿™é‡Œä½¿ç”¨ä¸“é—¨çš„ç®—æ³•å°†åˆ‡å‰²ä»£ç å†™å¾—ç´§å‡‘
        ç®—æ³•éœ€è¦æ‰¾è§„å¾‹æ€»ç»“å‡ºæ¥,ç›¸å¯¹ä¸å®¹æ˜“çœ‹å‡ºæ¥,ä¹Ÿå¯ä»¥è€ƒè™‘ä½¿ç”¨æ›´åŠ é€šä¿—çš„ç®—æ³•æ¥å‡åŒ€åˆ’åˆ†
        """
        q, r = divmod(len(lst), n)
        return [lst[i * q + min(i, r) : (i + 1) * q + min(i + 1, r)] for i in range(n)]

    def get_category_statistic(
        self, change_small_to_hotsale=True, hot_class=LanguagesHotSale
    ):
        """ç»Ÿè®¡åˆ†ç±»ä¿¡æ¯æŠ¥å‘Š"""
        category_statistic = self.category_statistic
        product_dict_lst = self.db_rows
        for idx, row in enumerate(product_dict_lst):
            category = row[DBProductFields.CATEGORIES.value]
            debug("processsing category: %s of row", category)

            if self.is_need_update_category(category):
                # debug("warn:category: [%s] of row to a best-saler category  ...", category)
                self.update_hotsale(
                    row=row,
                    hot_class=hot_class,
                    cat_field=DBProductFields.CATEGORIES.value,
                    language=self.language,
                )

            if category_statistic.get(category):
                category_statistic[category]["count"] += 1
                category_statistic[category]["product_lst"].append(
                    {"row_data": row, "row_index": idx}
                )
            else:
                category_statistic[category] = {
                    "count": 1,
                    "product_lst": [{"row_data": row, "row_index": idx}],
                }
        if change_small_to_hotsale:
            # cat_static_bakview=list(category_statistic.items())
            for category, cat_set in category_statistic.items():
                # cat_set = category_statistic[category]
                info("Info:category: %s, count: %s", category, cat_set["count"])
                if cat_set["count"] < self.category_threshold:
                    product_dict_lst = cat_set["product_lst"]
                    # äº‹å…ˆä¸ºå°ç±»åˆ†é…ç”Ÿæˆä¸€ä¸ªç±»ä¼¼çƒ­é”€çš„åˆ†ç±»
                    new_cat = hot_class.get_one_hot_sale_names(language=self.language)
                    cat = DBProductFields.CATEGORIES.value
                    # éå†æ‰€æœ‰äº§å“æ•°æ®å­—å…¸
                    for row in product_dict_lst:
                        # ä¿®æ”¹æ•°æ®è¡Œçš„åˆ†ç±»å­—æ®µ
                        # A1:ç›´æ¥å½±å“self.db_rowsä¸­çš„è¡Œ
                        # row[cat] = new_cat
                        row["row_data"][cat] = new_cat  # ä¿®æ”¹row_dataè€Œä¸æ˜¯rowæœ¬èº«
                        # A2:æ›´æ”¹çµæ´»çš„ç‹¬ç«‹æ§åˆ¶
                        # row_index = row["row_index"]
                        # self.db_rows[row_index][cat] = new_cat
                        info(
                            "Info:change small category to hotsale: %s->%s",
                            category,
                            new_cat,
                        )
            # æ–¹æ¡ˆ1:æ‰‹åŠ¨é€æ­¥å¤„ç†
            # å°†æ­¤ç±»ä¸­çš„äº§å“æ•°æ®è¡Œç§»åŠ¨(å¹¶å…¥)åˆ°çƒ­é”€ç±»åˆ«çš„äº§å“é›†ä¸­
            #         self.category_statistic[new_cat]["product_lst"].extend(rows_lst)
            #         # æ›´æ–°å¯¹åº”çƒ­å–è¯ä¸‹çš„äº§å“æ•°é‡
            #         self.category_statistic[new_cat]["count"] += cat_set["count"]
            #         # å°†å¯¹åº”çš„åˆ†ç±»ä»ç¼“å­˜ä¸­ç§»é™¤(å…·ä½“çš„åšæ³•åˆæœ‰å¤šç§,å¯ä»¥æœ€åç»Ÿä¸€è¿‡æ»¤æ‰å°ç±»,ç”¨å­—å…¸æ¨å¯¼å¼;æˆ–è€…åœ¨å¾ªç¯ä¸­åˆ é™¤,è¿­ä»£å¯¹è±¡æ˜¯åˆ—è¡¨çš„å‰¯æœ¬)
            #         # del self.category_statistic[category]
            # self.category_statistic = {
            #     k: v
            #     for k, v in self.category_statistic.items()
            #     if v["count"] >= self.category_threshold
            # }

            # æ–¹æ¡ˆ2: é‡æ–°ç»Ÿè®¡è½¬æ¢/åˆå¹¶å°ç±»åˆ«åçš„æƒ…å†µ(å…ˆæ¸…ç©ºåŸæ¥çš„ç»Ÿè®¡æ•°æ®,é˜²æ­¢å¹²æ‰°)
            self.category_statistic = {}
            self.get_category_statistic(change_small_to_hotsale=False)
        return self.category_statistic

    def is_need_update_category(self, category):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°åˆ†ç±»
        å½“åˆ†ç±»ä¸ºç©º,æˆ–è€…æ˜¯"!",æˆ–è€…æ˜¯"çƒ­å–"æ—¶,éœ€è¦æ›´æ–°åˆ†ç±»

        :param category: åˆ†ç±»åç§°
        :return: True/False
        """
        return not category or category == "!" or category == "çƒ­å–"

    def export_csv(
        self,
        dbs,
        out_dir="./",
        img_mode=ImageMode.NAME_AS_URL,
        split_files_size=10000,
        average_split_files=0,
        limit_sale=298.98,
        default_extension=".webp",
    ):
        """
        å¯¼å‡ºcsvæ–‡ä»¶
        :param file_path: æ–‡ä»¶è·¯å¾„
        :split_files: å•ä¸ªcsvæ–‡ä»¶æœ€å¤§è¡Œæ•°,é»˜è®¤ä¸º10000,å¦‚æœä¸èƒ½æ•´é™¤,åˆ™ä½™æ•°è¡Œæ•°ä¿å­˜åˆ°æœ€åä¸€ä»½;
        :average_split_files: å¹³å‡åˆ‡å‰²æ–‡ä»¶æ•°,é»˜è®¤ä¸º0,è¡¨ç¤ºä¸åˆ‡å‰²;
        :img_mode: æ˜¯å¦ä»…ä¿å­˜å›¾ç‰‡åä½œä¸º"å›¾ç‰‡å­—æ®µ"(ä¸€èˆ¬å¯ä»¥æŒ‡å®šäº§å“å›¾ç‰‡åå­—ä¸ºäº§å“sku),
            è€Œå›¾ç‰‡é“¾æ¥å­—æ®µå•ç‹¬ä¸€åˆ—(å›¾ç‰‡urlå­—æ®µ),ä¸‹è½½çš„æ—¶å€™ä¿å­˜ä¸ºskuåŒå
            è¿™æ ·å›¾ç‰‡å­—æ®µå¯ä»¥çœç•¥æ‰,ç„¶ååœ¨ä¸Šä¼ ä»£ç ä¸­å°†skuèµ‹å€¼ç»™å›¾ç‰‡å­—æ®µ,
            ä½†æ˜¯å¦‚æœè€ƒè™‘æ‰å…¶ä»–å›¢é˜Ÿä»£ç çš„å…¼å®¹æ€§,åˆ™å•ç‹¬ä¿ç•™,è€Œä¸”è¿˜å¯ä»¥è¿›ä¸€æ­¥è‡ªå®šå›¾ç‰‡åå­—ä¸º"sku+äº§å“å");
        :return: None
        """
        header = CSVProductFields.get_all_fields_name(img_mode=img_mode)
        header_for_woo = CSVProductFields.get_all_fields_value(img_mode=img_mode)
        warning("Info:csv header: %s", header_for_woo)
        # å‡†å¤‡å¥½æ•°æ®ğŸˆ
        lines = self.get_lines_dict_for_csv(
            dbs=dbs,
            img_mode=img_mode,
            default_extension=default_extension,
            # default_extension='.webp',
            limit_sale=limit_sale,
        )

        # self._export_csv(file_path, header, lines)
        # self.update_csv_header_inplace(file_path, header_for_woo)

        file_rows_lst = [lines]
        # å°†æ•°æ®è¡Œåˆ†å‰²æˆæ¯ä»½split_files_sizeä¸ªæ•°æ®,æˆ–è€…å°½å¯èƒ½å‡åŒ€çš„åˆ†æˆaverage_split_filesä»½æ•°æ®
        if split_files_size:
            file_rows_lst = [
                lines[i : i + split_files_size]
                for i in range(0, len(lines), split_files_size)
            ]
        elif average_split_files:
            file_rows_lst = self.split_list_average(lines, average_split_files)
        # if(file_rows_lst):

        for i, file_rows in enumerate(file_rows_lst):
            os.makedirs(out_dir, exist_ok=True)
            file_path = os.path.join(out_dir, f"p{i + 1}-{get_now_time_str()}.csv")
            file_path = os.path.abspath(file_path)
            self._export_csv(file_path=file_path, header=header, rows=file_rows)

            self._update_csv_header_inplace(
                file_path=file_path, new_headers=header_for_woo
            )

    def _export_csv(self, file_path, header, rows):
        """æ ¹æ®æ‰€ç»™çš„rowså¯¼å‡ºå•ä¸ªcsvæ–‡ä»¶

        param:file_path: csvæ–‡ä»¶è·¯å¾„
        param:header: è¡¨å¤´åˆ—è¡¨
        param:rows: æ•°æ®è¡Œåˆ—è¡¨
        """
        with open(file_path, "w", newline="", encoding="utf-8") as f:
            # writer = csv.writer(f)
            # writer.writerow(header)
            # writer.writerows(lines)
            writer = csv.DictWriter(f, fieldnames=header)
            writer.writeheader()
            writer.writerows(rows)
            # # å°†csvçš„è¡¨å¤´å­—æ®µåå­—è°ƒæ•´ä¸ºç¬¦åˆwoocommerceçš„è¦æ±‚
            # writer_woo=csv.DictWriter(f, fieldnames=header_for_woo)
            # writer_woo.writeheader()
        info(f"export csv file to [{file_path}]")

    def _update_csv_header_inplace(self, file_path, new_headers):
        """
        ç›´æ¥ä¿®æ”¹åŸCSVæ–‡ä»¶çš„è¡¨å¤´
        å‚æ•°:
            file_path: CSVæ–‡ä»¶è·¯å¾„
            new_headers: æ–°è¡¨å¤´åˆ—è¡¨
        """
        temp_file = file_path + ".tmp"
        with (
            open(file_path, "r", newline="", encoding="utf-8") as infile,
            open(temp_file, "w", newline="", encoding="utf-8") as outfile,
        ):
            reader = csv.reader(infile)
            writer = csv.writer(outfile)
            # è·³è¿‡æ—§è¡¨å¤´
            next(reader)
            # å†™å…¥æ–°è¡¨å¤´
            writer.writerow(new_headers)
            # å†™å…¥å‰©ä½™æ•°æ®
            writer.writerows(reader)
        # æ›¿æ¢åŸæ–‡ä»¶
        os.replace(temp_file, file_path)
        # é¢„è§ˆå‰5è¡Œæ•°æ®
        print(f"Preview of {file_path}(total lines:{len(pd.read_csv(file_path))}):")
        preview = pd.read_csv(file_path, nrows=5)[
            [
                CSVProductFields.SKU.value,
                CSVProductFields.IMAGES.value,
                CSVProductFields.CATEGORIES.value,
                # CSVProductFields.IMAGES_URL.value,
            ]
        ].head()
        print(preview)


if __name__ == "__main__":
    print("Welcome to use this woosqlitedb module!")
    logger.info("This module contain logging usage!")
    logger.warning("In default case,only warning messages will be printed!")
