"""
Woocommerce product handler/uploader for wordpress.
Copyright (C) 2025 cxxu1375. All Rights Reserved.

ä½¿ç”¨æ–‡æ¡£å’Œæ³¨æ„äº‹é¡¹,è¯·æŸ¥çœ‹Readme.mdæ–‡æœ¬æ–‡ä»¶(å¿…çœ‹)
å°¤å…¶æ˜¯é‡åˆ°é—®é¢˜,å¯ä»¥å‚è€ƒæ–‡æ¡£ä¸­çš„è¯´æ˜
"""

__author__ = "cxxu1375 <827797013@qq.com>"
__status__ = "production"
# The following module attributes are no longer updated.
__version__ = "1.0"
__date__ = "2025-04-07"
# %%

# è¯·å®‰è£…å¿…è¦çš„åº“(ä¸»è¦æ˜¯woocomeceåº“è¦ä¸‹è½½,ä¹Ÿå¯ä»¥è‡ªè¡Œæå–,å¤§å¤šæ˜¯è‡ªå¸¦æ— éœ€ä¸‹è½½çš„åº“)
# from typing import Literal
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from math import ceil
from datetime import datetime
import queue
import sys
from enum import Enum

# å…¶ä»–æ¨¡å—
import json
import csv
import html
import os
import copy
import pickle
import requests

from requests import Response
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
# from requests.exceptions import ConnectTimeout, ReadTimeout, Timeout, RequestException

# æ ¸å¿ƒåº“(éœ€è¦å®‰è£…)
from woocommerce import API
csv.field_size_limit(int(1e7))  # å…è®¸csvæ–‡ä»¶æœ€å¤§ä¸º10MB

##

# ç”¨æˆ·è¦é…ç½®çš„å‚æ•°ğŸˆ(ä»”ç»†æ£€æŸ¥ä¸‹é¢å†…å®¹)
protocal = "http"  # åè®®,ä¸€èˆ¬æ˜¯https(é€‚ç”¨äºæ­£å¼ä¸Šä¼ ),http(é€‚ç”¨äºæœ¬åœ°è„šæœ¬è°ƒè¯•/å¼€å‘)
domain = "wp.com"  # åŸŸå
url = f"{protocal}://{domain}"  # http://åŸŸå (ä¸è¦æœ‰å¤šä½™çš„è·¯å¾„)
consumer_key = "ck_cea9b0730bbda84628674625dc206495ddf62fc7"
consumer_secret = "cs_ba0185c197dc041ad8ba91915886395404badcb9"

# firebat
# consumer_key = "ck_bd5332370e52be2ee62f63204f75f6acaf796ebb"
# consumer_secret = "cs_f0c215137e0b9db09dfa4691cb080a6273f2f8fd"

# è¿™é‡ŒæŒ‡å®šç›®å½•,ä¸æ˜¯æ–‡ä»¶!ğŸˆ(æŒ‡å®šæ–‡ä»¶è¯·åˆ°å¤‡ç”¨æ–¹æ¡ˆ2ä¸­æŒ‡å®š)
CSV_DIR = r"./csv_dir/"
# CSV_DIR = r"C:/users/cxxu/Desktop"


# é¢å¤–å¯é…ç½®å‚æ•°
# æœ€å¤§æ€»çº¿ç¨‹æ•°ä¸è¶…è¿‡MAX_WORKERS_FILES * MAX_WORKERS_PER_FILE(ä¸¤è€…ä¹‹ç§¯)
#   ä½¿ç”¨filteredæ¨¡å¼(ä»…ä¸Šä¼ å°šæœªä¸Šä¼ çš„äº§å“)çš„æƒ…å†µä¸‹,ä»…MAX_WORKERS_FILESæœ‰æ•ˆ,
#   batchæ¨¡å¼ä¸‹,å…¶å†³å®šå°†éœ€è¦ä¸Šä¼ çš„æ•°æ®(å•ä¸ªé›†åˆ)ç”¨å‡ çº¿ç¨‹ä¸Šä¼ 
MAX_WORKERS_FILES = 2  # åŒæ—¶ä¸Šä¼ çš„æ–‡ä»¶æ•°(ä¸€èˆ¬ä¸è¶…è¿‡7);
MAX_WORKERS_PER_FILE = 1  # æ¯ä»½æ–‡ä»¶ä¸Šä¼ çš„çº¿ç¨‹æ•°
TIME_OUT = 100  # å¦‚æœæ˜¯æ‰¹ä¸Šä¼ ,å¯ä»¥è€ƒè™‘è°ƒå¤§äº›,é˜²æ­¢å“åº”ä½“è¿‡å¤§æ—¶é—´ä¸è¶³å¯¼è‡´æŠ¥é”™
BATCH_SIZE = 10  # æ¯æ¬¡ä¸Šä¼ çš„äº§å“æ•°é‡


# ä¸Šä¼ æ¨¡å¼åˆ—ä¸¾(å¯ä¾›ideè¡¥å…¨æç¤º);ç›¸å…³å«ä¹‰å¯ä»¥å‚è€ƒæ–‡æ¡£


class UploadMode(Enum):
    """äº§å“ä¸Šä¼ æ¨¡å¼æšä¸¾

    Attributes:
        JUMP_IF_EXIST: åˆ›å»ºå¤±è´¥æ—¶è·³è¿‡å½“å‰äº§å“ï¼ˆé»˜è®¤æ¨¡å¼ï¼‰
        TRY_CREATE_ONLY: ä»…å°è¯•åˆ›å»ºæ–°äº§å“ï¼Œå¦‚æœäº§å“å·²å­˜åœ¨åˆ™ä¸æ›´æ–°
        UPDATE_IF_EXIST: ç›´æ¥åˆ›å»ºå¤±è´¥æ—¶å°è¯•ç”¨PUTæ–¹æ³•æ›´æ–°äº§å“
        RESUME_FROM_DB: ä»æ•°æ®åº“æ¢å¤ä¸Šä¼ è¿›åº¦
        RESUME_FROM_LOG: ä»æ—¥å¿—æ–‡ä»¶æ¢å¤ä¸Šä¼ è¿›åº¦

    æ¨¡å¼è¯¦ç»†è¯´æ˜ï¼š
    1. JUMP_IF_EXIST (æ¨èé»˜è®¤)
       - è·³è¿‡å·²å­˜åœ¨çš„å•†å“
       - æ¯”TRY_CREATE_ONLYæœ‰æ›´å¥½çš„æ€§èƒ½è¡¨ç°
       - é€‚ç”¨åœºæ™¯ï¼šå¸¸è§„ä¸Šä¼ 
    2. TRY_CREATE_ONLY
       - ä»…åˆ›å»ºæ–°å•†å“
       - é‡åˆ°SKUå†²çªæ—¶ç›´æ¥è·³è¿‡
       - é€‚ç”¨åœºæ™¯ï¼šé¦–æ¬¡ä¸Šä¼ æˆ–ç¡®å®šæ— é‡å¤SKUæ—¶

    3. UPDATE_IF_EXIST (å¼ºåˆ¶æ›´æ–°)
       - è‡ªåŠ¨æ›´æ–°å·²å­˜åœ¨çš„å•†å“
       - é€‚ç”¨åœºæ™¯ï¼šéœ€è¦è¦†ç›–æ›´æ–°å•†å“ä¿¡æ¯æ—¶

    4. RESUME_FROM_DB (æ–­ç‚¹ç»­ä¼ )
       - ä»WooCommerceæ•°æ®åº“è¯»å–å·²ä¸Šä¼ è®°å½•
       - ä¼˜ç‚¹ï¼š100%å‡†ç¡®
       - ç¼ºç‚¹ï¼šé¦–æ¬¡æŸ¥è¯¢è¾ƒæ…¢

    5. RESUME_FROM_LOG (å¿«é€Ÿæ¢å¤)
       - ä»æœ¬åœ°æ—¥å¿—æ–‡ä»¶æ¢å¤è¿›åº¦
       - ä¼˜ç‚¹ï¼šæ¢å¤é€Ÿåº¦æå¿«
       - è¦æ±‚ï¼šå¿…é¡»ä½¿ç”¨æ­¤ä»£ç ç”Ÿæˆçš„æ—¥å¿—æ–‡ä»¶,æŒ‡å®šlogæ—¥å¿—æ–‡ä»¶è·¯å¾„
    """

    JUMP_IF_EXIST = "jump_if_exist"
    TRY_CREATE_ONLY = "try_create_only"
    UPDATE_IF_EXIST = "update_if_exist"
    RESUME_FROM_DATABASE = "resume_from_database"
    RESUME_FROM_LOG_FILE = "resume_from_log_file"


class FetchMode(Enum):
    """äº§å“è·å–æ¨¡å¼æšä¸¾

    Attributes:
        FROM_CACHE: ä»ç¼“å­˜ä¸­è·å–äº§å“
        FROM_DATABASE: ä»æ•°æ®åº“ä¸­æ¢å¤è¿›åº¦
        FROM_LOG_FILE: ä»æœ¬åœ°æ—¥å¿—æ–‡ä»¶æ¢å¤è¿›åº¦

    """

    FROM_CACHE = "from_cache"
    FROM_DATABASE = "from_database"
    FROM_LOG_FILE = "from_log_file"


class ProgressTracker:
    """
    åˆå§‹åŒ–MyClassç±»çš„å®ä¾‹ã€‚

    è¯¥æ„é€ å‡½æ•°åˆå§‹åŒ–äº†ä¸€ä¸ªåä¸ºprogress_countçš„å®ä¾‹å˜é‡ï¼Œç”¨äºè·Ÿè¸ªè¿›åº¦è®¡æ•°ã€‚
    """

    def __init__(self):
        self.progress_count = 0
        self.success_count = 0
        self.fail_count = 0

    def update_progress(self, count_type="success"):
        """æ›´æ–°è®¡æ•°å™¨(è‡ªå¢+1)"""

        # å§‹ç»ˆä¸ºself.progress_count+1
        self.progress_count += 1

        if count_type == "success":
            self.success_count += 1
        elif count_type == "fail":
            self.fail_count += 1

        # print(f"Progress count: {self.progress_count}")

    def get_updated_progress_str(self, count_type="success"):
        """è·å–æ›´æ–°åçš„è¿›åº¦å­—ç¬¦ä¸²,ä¾¿äºç»Ÿä¸€æ ¼å¼"""
        self.update_progress(count_type=count_type)
        return f"[{self.progress_count}({self.success_count} success, {self.fail_count} fail)]"


# pt = ProgressTracker()
# é»˜è®¤é€‰æ‹©çš„ä¸Šä¼ æ¨¡å¼:
UPLOAD_MODE = UploadMode.TRY_CREATE_ONLY

# æ—¥å¿—æ–‡ä»¶è·¯å¾„,å¯ä½œä¸ºå­˜æ¡£,æ¢å¤ä¸Šä¼ æ–­ç‚¹ğŸˆ
TIME_STR = datetime.now().strftime("%Y%m%d-%H-%M-%S")
CSV_DIR = CSV_DIR.strip("/")
LOG_FILE_UPLOAD = f"{CSV_DIR}/log/upload-{domain}-{TIME_STR}.csv"
LOG_FILE_UPLOAD_BAK = f"C:/log/upload-{domain}.csv"
# LOG_FILE_UPLOAD_FAIL=f"{CSV_DIR}/log/upload_fail-{domain}-{time_str}.csv"


# ä¸»æ¨æ–¹æ¡ˆ:è·å–æŒ‡å®šç›®å½•ä¸‹çš„csvæ–‡ä»¶åˆ—è¡¨
files_from_dir = os.listdir(CSV_DIR)
dir_csv_files = [os.path.join(CSV_DIR, f) for f in files_from_dir if f.endswith(".csv")]


# å¤‡ç”¨æ–¹æ¡ˆ1:è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å,å¦‚æœæ–‡ä»¶åæ¯”è¾ƒè§„èŒƒ(å¯é€‰)
# æ¯”å¦‚range(1,7),å°†ç¼–å·1,2,...,6(å·¦é—­å³å¼€æ•´æ•°åŒºé—´)
# æŒ‡å®šè¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
auto_csv_files = [os.path.join(CSV_DIR, f"p{i}.csv") for i in range(1, 7)]

# å¤‡ç”¨æ–¹æ¡ˆ2:æ‰‹åŠ¨æŒ‡å®šæ–‡ä»¶åˆ—è¡¨é…ç½®(å¯é€‰)
manual_csv_files = [
    "  ./p1.csv  ",
    "  C:/path/x.csv  ",
]

# æŒ‡å®šä½ çš„æ–‡ä»¶åˆ—è¡¨(ä»ä¸Šè¿°ä¸‰ç§æ–¹æ¡ˆä¸­é€‰æ‹©ä¸€ç§,æ¨èä½¿ç”¨æ–¹æ¡ˆ1)

files = dir_csv_files

##
# -----------------------------------------------------------------------------
# æ—¥å¿—æ¶ˆæ¯é˜Ÿåˆ—
log_queue = queue.Queue()
# åˆ†ç±»ç¼“å­˜é”categories_cache_lock
cat_lock = threading.Lock()
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
##

# å®šä¹‰ WooCommerce API ç«¯ç‚¹å¸¸é‡å­—ç¬¦ä¸²
# æ ¹æ®apiçš„è§„èŒƒ,rest api(get/post/put/delete)ä¸­çš„è·¯å¾„å­—ç¬¦ä¸²è¢«å½¢å‚è¢«ç§°ä¸º"endpoint"
CATEGORIES_ENDPOINT = "products/categories"
CATEGORIES_TOTALS_ENDPOINT = "reports/categories/totals"


PRODUCTS_ENDPOINT = "products"
PRODUCTS_TOTALS_ENDPOINT = "reports/products/totals"
PRODUCT_BATCH_ENDPOINT = "products/batch"

SYSTEM_STATUS_ENDPOINT = "system_status"

# -----------------------------------------------------------------------------------

##


def download_img_to_local(img_url, product_sku):
    """
    ä¸‹è½½è¿œç¨‹å›¾ç‰‡å¹¶ä¿å­˜åˆ°æœ¬åœ°
    :param url: å›¾ç‰‡çš„URL
    :param product_sku: äº§å“çš„SKUï¼Œç”¨äºå‘½åæœ¬åœ°å›¾ç‰‡
    :return: æœ¬åœ°å›¾ç‰‡è·¯å¾„
    """
    local_filename = f"{product_sku}.jpg"
    with requests.get(img_url, stream=True, timeout=10) as r:
        r.raise_for_status()
        with open(local_filename, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
    return local_filename


def split_list(lst, n):
    """å°†å¯è¿­ä»£å®¹å™¨(ä¾‹å¦‚åˆ—è¡¨)å¹³å‡åˆ†ä¸ºnä»½,è¿”å›åˆ†å‰²åçš„åˆ—è¡¨
    å°½å¯èƒ½çš„å¹³å‡åˆ†é…æ¯”è¾ƒå¥½,å¦‚æœå‰n-1ä»½æ•°é‡ç›¸åŒ,ä¸”
    å°†ä½™æ•°å…ƒç´ éƒ½æ”¾åˆ°æœ€åä¸€ä»½å¯èƒ½ä¼šå¯¼è‡´æœ€åä¸€ä»½å…ƒç´ è¿‡å¤š(æœ€åæƒ…å†µä¸‹æ˜¯å¹³å‡ä»½çš„è¿‘ä¸¤å€)
    æ–¹æ¡ˆ1:æ¨è
    è®¾ä½ è¦å‡åˆ†ä¸ºnä»½,æ¯ä»½çš„åŸºæœ¬å¤§å°ä¸ºsize=len(lst)//n,ä½™æ•°ä¸ºr=len(lst)%n,ä¸”ä¸€å®šæœ‰(r<n)
    é‚£ä¹ˆå‰rä»½æ¯ä»½å«æœ‰size+1ä¸ªå…ƒç´ ï¼Œån-rä»½æ¯ä»½å«æœ‰sizeä¸ªå…ƒç´ 
    æ­¤æ–¹æ¡ˆå¯ä»¥ä¿è¯,ä»»æ„ä¸¤ä»½æ‰€åˆ†å¾—çš„å…ƒç´ æ•°é‡å·®ä¸ä¼šè¶…è¿‡1
    å¦‚æœnå¤§äºlstçš„å…ƒç´ æ•°é‡,é‚£ä¹ˆå‰len(lst)ä»½æ¯ä»½å«æœ‰1ä¸ªå…ƒç´ ,ån-len(lst)ä»½æ¯ä»½å«æœ‰0ä¸ªå…ƒç´ (ç©ºåˆ—è¡¨)

    æ–¹æ¡ˆ2:ä¸æ¨è
    å¦‚æœå®¹å™¨ä¸­å…ƒç´ é•¿åº¦ä¸ºL=len(lst),kä¸ºL/nçš„ä½™æ•°,åˆ™å°†æœ€åkä¸ªå…ƒç´ å½’å…¥æœ€åä¸€ä»½

    Parameters
    ----------
    lst : list
        éœ€è¦è¢«åˆ†å‰²çš„å®¹å™¨åˆ—è¡¨
    n : int
        éœ€è¦è¢«åˆ†å‰²çš„ä»½æ•°(å¹³å‡)

    Returns
    -------
    list
        åˆ†å‰²åçš„åˆ—è¡¨çš„åˆ—è¡¨
    Examples
    --------
    split_list(list(range(1,11)), 4)


    """
    result = []
    size, r = divmod(len(lst), n)
    print(f"size: {size}, r: {r}")

    size_r = size + 1
    for i in range(r):
        start = i * size_r
        end = (i + 1) * size_r
        result.append(lst[start:end])
    start = (size + 1) * r

    for i in range(r, n):
        end = start + size
        result.append(lst[start:end])
        start = end

    return result


LOG_HEADER = ["SKU", "Name", "id", "Status", "message", "datetime"]


def log_worker(log_file=LOG_FILE_UPLOAD):
    """åå°æ—¥å¿—è®°å½•çº¿ç¨‹
    åˆ©ç”¨å¾ªç¯ä¸æ–­å°è¯•ä»å…¨å±€æ—¥å¿—é˜Ÿåˆ—ä¸­è·å–æ—¥å¿—æ¡ç›®,ç„¶åå†™å…¥åˆ°æ—¥å¿—æ–‡ä»¶ä¸­
    log_header å‚è€ƒ:["Timestamp", "RecordID", "Status", "Details", "ProcessingTime"]

    """
    print(f"Log worker started.logs will be written to: {log_file}ğŸˆ")
    while True:
        log_entry = log_queue.get()
        # print(f"Log worker got log entry: {log_entry}")
        if log_entry is None:  # ç»ˆæ­¢ä¿¡å·
            break
        try:
            # æ£€æŸ¥è·¯å¾„(ç›®å½•)å­˜åœ¨,è‹¥ä¸å­˜åœ¨åˆ™åˆ›å»º
            log_dir = os.path.dirname(log_file)
            if not os.path.exists(log_dir):
                os.makedirs(log_dir)
            # å†™å…¥æ—¥å¿—æ–‡ä»¶
            with open(log_file, "a", newline="", encoding="utf-8") as f:

                writer = csv.writer(f)
                # å¦‚æœæ–‡ä»¶ä¸ºç©ºï¼Œå†™å…¥æ ‡é¢˜è¡Œ
                if f.tell() == 0:
                    writer.writerow(LOG_HEADER)
                writer.writerow(log_entry)
        except Exception as e:
            print(f"Error:Log write failed: {e}")
        finally:
            log_queue.task_done()


def log_upload(sku, name, product_id, status, msg=""):
    """å°†æ—¥å¿—åŠ å…¥åˆ°æ—¥å¿—æ¶ˆæ¯é˜Ÿåˆ—ä¸­
    è¡¨å¤´ç»“æ„ç”±å¸¸é‡LOG_HEADERå®šä¹‰,å…ƒç´ é¡ºåºä¸LOG_HEADERä¸€è‡´,æˆ–è€…ä½¿ç”¨å…³é”®å­—å‚æ•°ä¼ å‚
    """
    log_entry = [
        sku,
        name,
        product_id,
        status,
        msg,
        datetime.now().isoformat(),
    ]
    log_queue.put(log_entry)
    # print(f"Log preview:{log_entry}")
    return log_entry


def cleanup_log_thread(q_thread):
    """æ¸…ç†å‡½æ•°ï¼Œç­‰å¾…é˜Ÿåˆ—å¤„ç†å®Œæˆå¹¶åœæ­¢å·¥ä½œçº¿ç¨‹"""
    log_queue.join()  # ç­‰å¾…æ‰€æœ‰æ—¥å¿—é¡¹å¤„ç†å®Œæˆ
    log_queue.put(None)  # å‘é€ç»ˆæ­¢ä¿¡å·
    q_thread.join()  # ç­‰å¾…çº¿ç¨‹ç»“æŸ
    print("log_thread(daemon) end.")


##


class WC(API):
    """WooCommerce äº§å“ä¸Šä¼ å™¨
    query_string_auth=True
    # Force Basic Authentication as query string true and using under HTTPS Authentication over HTTP
    """

    def __init__(
        self,
        api_url=url,
        api_consumer_key=consumer_key,
        api_consumer_secret=consumer_secret,
        timeout=TIME_OUT,
        version="wc/v3",
        wp_api=True,
        query_string_auth=False,  # ä½¿ç”¨æŸ¥è¯¢å­—ç¬¦ä¸²è®¤è¯ï¼Œè€Œä¸æ˜¯åŸºæœ¬è®¤è¯
    ):
        """WCç”Ÿæˆå™¨
        æ­¤ç±»å‹è®¾ç½®äº†ä¸¤ä¸ªæˆå‘˜å˜é‡,wcapiå’Œexisting_products,åˆ†åˆ«è¡¨ç¤ºWooCommerce APIå®¢æˆ·ç«¯å’Œç¼“å­˜çš„ç°æœ‰äº§å“ä¿¡æ¯
        å¦‚æœä¸è€ƒè™‘é‡å¤,å¯ä»¥ä¸ä½¿ç”¨existing_productsç¼“å­˜,ç›´æ¥ä½¿ç”¨APIä¸Šä¼ äº§å“

        Parameters
        ----------
        url : str, optional
            WooCommerce ç«™ç‚¹ URL(å¯ä»¥æ˜¯æœ¬åœ°ç«™ç‚¹httpé“¾æ¥,ä¹Ÿå¯ä»¥æ˜¯httpsé“¾æ¥), by default "http..."
        consumer_key : str, optional
            WooCommerce ç«™ç‚¹çš„ Consumer Key, by default "ck_..."
        consumer_secret : str, optional
            WooCommerce ç«™ç‚¹çš„ Consumer Secret, by default "cs_..."
        version : str, optional
            woo apiç‰ˆæœ¬ç›®å‰ä½¿ç”¨v3ç‰ˆæœ¬, by default "wc/v3"
        """

        super().__init__(
            url=api_url,
            consumer_key=api_consumer_key,
            consumer_secret=api_consumer_secret,
            version=version,
            wp_api=wp_api,
            query_string_auth=query_string_auth,
            timeout=timeout,
        )

        # åˆå§‹åŒ–è¿æ¥æ± 
        self._init_session()
        # ç¼“å­˜æˆå‘˜å˜é‡

        # å·²å­˜åœ¨çš„å…·æœ‰skuçš„äº§å“ä¿¡æ¯ï¼Œé”®ä¸º SKU(ä½¿ç”¨å­—å…¸å­˜å‚¨,æŸ¥è¯¢æ€§èƒ½æé«˜)
        self.existing_products_sku = {}
        # è€ƒè™‘åˆ°ä¸€ä¸ªäº§å“ä¸€å®šæœ‰(éç©º)çš„å­—æ®µæ˜¯id,è¿™é‡Œè¦æ”¶é›†id,å–å€¼å¯ä»¥æ˜¯name,sku ç­‰
        self.existing_products = {}
        # ç¼“å­˜æŸ¥è¯¢çš„é¡µé¢,å¯ä»¥è‡ªè¡Œè½¬æ¢åˆ°existing_productsä¸­
        self.product_pages = []
        # ç¼“å­˜å·²å­˜åœ¨çš„åˆ†ç±»ä¿¡æ¯ï¼Œé”®ä¸ºåˆ†ç±»åç§°
        self.existing_categories = {}
        # è®°å½•ä¸Šä¼ å¤±è´¥çš„äº§å“ä¿¡æ¯(æ¯”å¦‚è¶…æ—¶)
        self.upload_failed_products = []

        # ç¼“å­˜ä»æœ¬åœ°æ–‡ä»¶è¯»å–åˆ°çš„äº§å“æ•°æ®(åˆ—è¡¨å…ƒç´ å¯ä»¥æ˜¯æ¯ä¸€è¡Œcsvæ•°æ®æ„æˆçš„å­—å…¸)
        self.product_from_file = []
        # å°šæœªä¸Šä¼ çš„äº§å“æ•°æ®(åˆ—è¡¨å…ƒç´ å¯ä»¥æ˜¯æ¯ä¸€è¡Œcsvæ•°æ®æ„æˆçš„å­—å…¸)
        self.products_need_to_upload = []
        # ä¸Šä¼ è¿›åº¦è·Ÿè¸ªå™¨
        self.progress_tracker = ProgressTracker()

    def _init_session(self):
        """åˆå§‹åŒ–å¸¦è¿æ¥æ± çš„session"""
        self.session = requests.Session()

        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3, backoff_factor=1, status_forcelist=[408, 429, 500, 502, 503, 504]
        )

        # é…ç½®è¿æ¥æ± 
        adapter = HTTPAdapter(
            pool_connections=20,
            pool_maxsize=20,
            pool_block=False,
            max_retries=retry_strategy,
        )

        # ä¸ºHTTPå’ŒHTTPSæŒ‚è½½é€‚é…å™¨
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    def _request(self, method, endpoint, data, params=None, **kwargs):
        """é‡å†™è¯·æ±‚æ–¹æ³•ä»¥ä½¿ç”¨æˆ‘ä»¬çš„è¿æ¥æ± session"""
        # ç¡®ä¿ä½¿ç”¨æˆ‘ä»¬è‡ªå®šä¹‰çš„session
        kwargs["session"] = self.session

        # è°ƒç”¨çˆ¶ç±»çš„_requestæ–¹æ³•
        return super().__request(
            method=method, endpoint=endpoint, data=data, params=params, **kwargs
        )

    def get_system_status(self):
        """è·å–wordPressç«™ç‚¹çš„ç³»ç»ŸçŠ¶æ€/ä¿¡æ¯"""
        response = self.get(SYSTEM_STATUS_ENDPOINT)
        return response

    def dump_existing_products_sku_pkl(
        self, mode="existing_products_sku", path=f"{domain}-existing_products_sku.pkl"
    ):
        """å¯¼å‡ºç°æœ‰äº§å“çš„å¯¹è±¡(pickleæ–‡ä»¶)
        æ ¹æ®å›¢é˜Ÿçš„ä¸šåŠ¡æ–¹ä¾¿,è¿™é‡Œä»…å¯¼å‡ºæœ‰skuçš„products
        ä¸šåŠ¡å˜æ›´å¯ä»¥æŠŠæ›´å®Œæ•´çš„existing_productsä¹Ÿå¯¼å‡ºæ¥,æˆ–è€…ä»£æ›¿æ‰
        Parameters
        ----------
        mode : str, optional
            å¯¼å‡ºæ¨¡å¼
            "existing_products_sku"å¯¼å‡ºæœ‰skuçš„products
            "existing_products"å¯¼å‡ºæ‰€æœ‰products
            by default "existing_products_sku"
        path : str, optional

            pklæ–‡ä»¶çš„ä¿å­˜è·¯å¾„, by default f"{domain}-existing_products.pkl"
        """
        products_to_export = {}
        if mode == "existing_products_sku":

            products_to_export = self.existing_products_sku
        elif mode == "existing_products":
            products_to_export = self.existing_products
        else:
            print(f"export mode {mode} not supported!")
        with open(path, "wb") as f:
            pickle.dump(products_to_export, f)

    def load_existing_products_sku_pkl(
        self, mode="existing_products_sku", path=f"{domain}-existing_products.pkl"
    ):
        """å¯¼å…¥ç°æœ‰äº§å“çš„å¯¹è±¡(pickleæ–‡ä»¶)
        :param path: pickleæ–‡ä»¶è·¯å¾„, by default f"{domain}-existing_products.pkl"
        :param mode: å¯¼å…¥æ¨¡å¼,é»˜è®¤ä¸º"existing_products_sku",è¡¨ç¤ºå¯¼å…¥æœ‰skuçš„products,
            å¦‚æœé€‰æ‹©"existing_products",åˆ™å¯¼å…¥æ‰€æœ‰products, by default "existing_products_sku"
        :return: å¯¼å…¥çš„productså¯¹è±¡
        """
        products_to_import = {}

        with open(path, "rb") as f:
            products_to_import = self.existing_products = pickle.load(f)
            if mode == "existing_products_sku":
                self.existing_products_sku = products_to_import
            elif mode == "existing_products":
                self.existing_products = products_to_import
            else:
                print(f"import mode {mode} not supported!")
        return products_to_import

    def get_category(self, category_name, use_lock=True):
        """
        æ ¹æ®æŒ‡å®šçš„åˆ†ç±»åå­—,æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨æ­¤åˆ†ç±»,å¦‚æœå·²å­˜åœ¨,è·å–åˆ†ç±»çš„ IDï¼Œå¦‚æœåˆ†ç±»ä¸å­˜åœ¨åˆ™åˆ›å»ºè¯¥åˆ†ç±»ã€‚
        æ­¤æ–¹æ³•æ¯æ¬¡ä»…å¤„ç†ä¸€ä¸ªåˆ†ç±»åå­—
        å¯¹äºä»csvä¸­è¯»å–çš„åˆ†ç±»å€¼,å¯ä»¥ç”¨get_categoriesæ–¹æ³•è§£æå¹¶å¤„ç†å¤šä¸ªåˆ†ç±»å€¼(ä¹Ÿå…¼å®¹å•ä¸ªåˆ†ç±»åå­—)
        ---
        æ­¤æ–¹æ³•ä½¿ç”¨åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼,é¿å…å¤šçº¿ç¨‹åŒæ—¶åˆ›å»ºåŒä¸€åˆ†ç±»å¹¶å°½å¯èƒ½é™ä½ä¸å¿…è¦é˜»å¡çš„å‡ºç°


        :param category_name: åˆ†ç±»åç§°
        :param no_lock: æ˜¯å¦ä½¿ç”¨é”å®šæ¨¡å¼,é»˜è®¤ä¸ä½¿ç”¨,å¦‚æœä½¿ç”¨,åˆ™å¯èƒ½å¯¼è‡´å¤šçº¿ç¨‹åŒæ—¶åˆ›å»ºåŒä¸€åˆ†ç±»,
            å¯¼è‡´èµ„æºæµªè´¹,åœ¨ä½ ç¡®å®šæ²¡æœ‰åˆ†ç±»æˆ–è€…æ— æ‰€è°“é‡å»ºçš„æƒ…å†µä¸‹å¯ä»¥è®¾ç½®True
        :return: åˆ†ç±» ID

        æŸ¥è¯¢åˆ†ç±»æ˜¯å¦å­˜åœ¨(ç›®å‰apiæ­£å¼å¼€æ”¾çš„å‚æ•°åªæœ‰id,slugæˆ–è®¸ä¹Ÿè¡Œ,ä½†æ˜¯å¯¹äºå­—ç¬¦å¤æ‚çš„åˆ†ç±»,æˆ‘ä»¬åˆ©ç”¨pythonå°†éš¾ä»¥è½¬æ¢ä¸ºslug)
        å¯ä»¥è€ƒè™‘å…ˆè·å–æ‰€æœ‰åˆ†ç±»æ„æˆçš„å¯è¿­ä»£å¯¹è±¡,ç„¶åå†é€šè¿‡æŸ¥è¯¢åå­—è·å–id
        response = self.wcapi.get(
            categories_endpoint,
            params={
                # "name": category_name
                # "id": category_id
                "slug": category_name.lower()
            }
        )
        """
        if category_name in self.existing_categories:
            return self.existing_categories[category_name]

        # å¦‚æœå­˜åœ¨,åˆ™è¿”å›ID
        cat_res = self.existing_categories.get(category_name)
        if cat_res:
            print(f"category: {category_name} exist! The id is {cat_res}")
            return cat_res
        else:
            # å¦‚æœåˆ†ç±»ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
            if use_lock:
                with cat_lock:
                    # åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼(é˜²æ­¢å…¶ä»–è¿›ç¨‹å·²ç»åˆ›å»ºå¥½äº†åŒä¸€åˆ†ç±»),è¿™é‡Œé‡å¤åˆ›å»ºå°±ä¼šå‡ºé”™ä¸”æµªè´¹èµ„æº
                    self._create_category(category_name)
            else:
                self._create_category(category_name)

    def _create_category(self, category_name):
        if category_name in self.existing_categories:
            return self.existing_categories[category_name]
        # åŠ é”,é¿å…å¤šçº¿ç¨‹åŒæ—¶åˆ›å»ºåŒä¸€åˆ†ç±»
        print(f"Creating new category: {category_name}")
        # åˆ›å»ºæ–°åˆ†ç±»(åªæœ‰åˆ†ç±»åå­—)
        response = self.post(CATEGORIES_ENDPOINT, {"name": category_name})
        if response.ok:
            category_id = response.json()["id"]
            self.existing_categories[category_name] = category_id
            print("\tOK:Create new category")
            return category_id
        else:
            print(
                f"\tFailed:Create new category \
                    {category_name}: {self.get_code_message(response)}"
            )
        return None

    def get_categories(self, categories_str, mandatory=True):
        """
        å¤„ç†äº§å“åˆ†ç±»å­—ç¬¦ä¸²ï¼Œè¿”å›åˆ†ç±» ID åˆ—è¡¨ã€‚
        äº§å“å°†è¢«æ·»åŠ åˆ°åˆ†ç±»IDåˆ—è¡¨ä¸­æ‰€æŒ‡çš„åˆ†ç±»

        è¿™é‡Œå…è®¸äº§å“æœ‰å¤šä¸ªåˆ†ç±»,åˆ†ç±»ä¹‹é—´ç”¨é€—å·åˆ†å‰²;
        å¦‚æœåˆ†ç±»æ˜¯å•ä¸€çš„,ä¹Ÿå¯ä»¥å¤„ç†,ä½†æ˜¯æ³¨æ„é€—å·è¢«ä½œä¸ºåˆ†éš”ç¬¦
        æˆ–è€…ä¸ä½¿ç”¨æ­¤æ–¹æ³•,ç›´æ¥ç”¨get_or_create_category ç®€åŒ–å¤„ç†

        :param categories_str: åˆ†ç±»å­—ç¬¦ä¸²ï¼ˆå¤šä¸ªåˆ†ç±»ä»¥é€—å·åˆ†éš”ï¼‰ã€‚
        :param mandatory: æ˜¯å¦å¿…é¡»å­˜åœ¨åˆ†ç±»,é»˜è®¤ä¸ºTrue,å¦‚æœä¸ºFalse,åˆ™å…è®¸è¿”å›ç©ºåˆ—è¡¨
        :return: åŒ…å«åˆ†ç±» ID çš„åˆ—è¡¨ã€‚
        """
        category_ids = []
        if not categories_str:
            if mandatory:
                raise ValueError("Product must have at least one category.")
        # å¦‚æœä½ çš„äº§å“çš„æ‰€å±åˆ†ç±»å­—ç¬¦ä¸²æŒ‰é€—å·åˆ†éš”,é‚£ä¹ˆé€šè¿‡splitæ–¹æ³•è§£ææ‹†åˆ†å¤„ç†
        # ä½†æ˜¯ç›®å‰æˆ‘ä»¬çš„ä¸šåŠ¡å°±æ˜¯å•åˆ†ç±»å­—ç¬¦ä¸²,å¯ä»¥è€ƒè™‘ä¸éœ€è¦split
        category_names = [cat.strip() for cat in categories_str.split(",")]
        category_ids = []

        for category_name in category_names:
            category_id = self.get_category(category_name)
            if category_id:
                category_ids.append({"id": category_id})

        return category_ids

    def get_all_categories_from_file(self, csv_files):
        """ä»æ–‡ä»¶åˆ—è¡¨ä¸­è¯»å–åˆ†ç±»ä¿¡æ¯,å¾—åˆ°åˆ†ç±»é›†åˆ

        Parameters
        ----------
        csv_files : list[str]
            woocommerce csvæ–‡ä»¶åˆ—è¡¨
        """
        if isinstance(csv_files, str):
            csv_files = [csv_files]
        categories = set()
        for file in csv_files:
            with open(file, mode="r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # set.add(categories, row["Categories"])
                    categories.add(row["Categories"])
        return categories

    def get_worker_number(self, tasks, max_workers):
        """è¿”å›éœ€è¦åˆ›å»ºçš„workeræ•°(æœ€å¤§çº¿ç¨‹æ•°)
        æ¯”è¾ƒä»»åŠ¡æ€»æ•°å’Œæœ€å¤§çº¿ç¨‹æ•°ä¸­è¾ƒå°çš„ä¸€ä¸ª
        çº¿ç¨‹æ•°è‡³å°‘ä¸º1

        Parameters
        ----------
        tasks : int
            ä»»åŠ¡æ€»æ•°
        max_workers : int
            æœ€å¤§çº¿ç¨‹æ•°
        """
        return max(min(tasks, max_workers), 1)

    def prepare_categories(self, csv_files, max_workers=50):
        """ä»æ–‡ä»¶åˆ›å»ºåˆ†ç±»

        Parameters
        ----------
        csv_files : str
            woocommerce csvæ–‡ä»¶åˆ—è¡¨
        max_workers : int, optional
            å¹¶å‘çº¿ç¨‹æ•°
        """
        # å‡†å¤‡åˆ†ç±»å‰è¦å…ˆæ£€æŸ¥ç«™ç‚¹æ˜¯å¦å­˜åœ¨æŸäº›åˆ†ç±»,é˜²æ­¢å†²çªå‘ç”Ÿ
        self.fetch_existing_categories(mode=FetchMode.FROM_DATABASE)

        categories = self.get_all_categories_from_file(csv_files)

        workers = self.get_worker_number(len(categories), max_workers)
        print(f"with {workers} workers(threads) create categories...")

        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = [
                executor.submit(self.get_category, category) for category in categories
            ]
            for future in as_completed(futures):
                future.result()

        # for category in categories:
        #     self.get_categories(category)

    def delete_categories(self, category_id="", category_name="", mode="specified"):
        """åˆ é™¤åˆ†ç±»
        æ”¯æŒåˆ é™¤æŒ‡å®šåˆ†ç±»æˆ–å…¨éƒ¨åˆ†ç±»
        å¦‚æœè¦åˆ é™¤æŒ‡å®šåˆ†ç±»,å¯ä»¥åˆ©ç”¨å¾ªç¯è°ƒç”¨æ­¤æ–¹æ³•é—´æ¥å®ç°
        å¦‚æœè¦åˆ é™¤å…¨éƒ¨åˆ†ç±»,å¯ä»¥è°ƒç”¨æ­¤æ–¹æ³•,modeå‚æ•°è®¾ç½®ä¸º"all"

        Parameters
        ----------
        category_id : str, optional
            åˆ†ç±»id, by default ""
        mode : str, optional
            åˆ é™¤æ¨¡å¼, "specified"è¡¨ç¤ºåˆ é™¤æŒ‡å®šåˆ†ç±»,
              "all"è¡¨ç¤ºåˆ é™¤æ‰€æœ‰åˆ†ç±», by default "specified"

        Returns
        -------
        Response List
            è¿”å›è¢«åˆ é™¤çš„åˆ†ç±»çš„å“åº”
        """
        res = []
        if mode == "specified":
            if category_name:
                # å…ˆè·å–åˆ†ç±»id
                category_id = self.existing_categories.get(category_name)
                if not category_id:
                    print(f"category: {category_name} not exist!")
                    return res
                else:
                    print(f"Deleting category: {category_name} (ID: {category_id})")
            # åŒä¸€å¾—åˆ°åˆ†ç±»idå,æ ¹æ®idåˆ é™¤åˆ†ç±»
            response = self.delete(
                f"{CATEGORIES_ENDPOINT}/{category_id}", params={"force": True}
            )
            res.append(response)

        elif mode == "all":
            response = self.get(CATEGORIES_ENDPOINT)
            if response.ok:
                for category in response.json():
                    response = self.delete_categories(
                        category_id=category["id"], mode="specified"
                    )
                    res.append(response)

            else:
                print(f"Failed to fetch categories: {self.get_code_message(response)}")
        else:
            print(f"Invalid mode: {mode}")
        return res

    def fetch_existing_products(
        self,
        page=1,
        page_size=100,
        max_workers=10,
        fetch_mode=FetchMode.FROM_CACHE,
        log_file="",
    ):
        """è·å–æ‰€æœ‰ç°æœ‰äº§å“çš„ SKU å’Œ ID

        Parameters
        ----------
        max_workers : int, optional
            æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°, by default 10
            è®¾ç½®è¿‡å¤§å¯èƒ½ä¼šå¯¼è‡´ConnectionError
        mode : str, optional

            1.FetchMode.FROM_CACHE,åˆ™ä»ç¼“å­˜ä¸­è·å–(é€Ÿåº¦å¿«,ä½†æ˜¯æœªå¿…æ˜¯æœ€æ–°æƒ…å†µ,ä¸ä¸€å®šåŒ…å«å…¨éƒ¨äº§å“);

            2.FetchMode.FROM_DATABASE,åˆ™è°ƒç”¨apiæŸ¥è¯¢æ•°æ®åº“è·å–(é€Ÿåº¦æ…¢,å°½é‡ä¸ç”¨), by default FetchMode.FROM_CACHE

            3.FetchMode.FROM_LOG_FILE,ä»æ—¥å¿—ä¸­æ¢å¤å•†å“ä¸Šä¼ è¿›åº¦(è¯»æ¡£),é€Ÿåº¦æœ€å¿«,ä¼˜å…ˆè€ƒè™‘
        log_file : str, optional
            æ—¥å¿—æ–‡ä»¶è·¯å¾„, by default ""


        ç¤ºä¾‹è¾“å‡º:
        {'SK0003245-U': 122578, 'SK0003244-U': 122576, 'SK0003243-U': 122574, 'SK0003242-U': 122572}
        """
        print(f"Fetch {{Mode: {fetch_mode}}}")
        # å¾ªç¯æŸ¥è¯¢æ‰€æœ‰äº§å“,æ¯æ¬¡è·å–ä¸€å®šæ•°é‡çš„äº§å“(æ¯æ¬¡æœ€å¤š100ä¸ªäº§å“)
        if fetch_mode == FetchMode.FROM_CACHE:
            if not self.existing_products_sku:
                print(
                    "Fetch Mode Changed!:Fetching products from database...\
                            (There is no cached products.)"
                )
                self.fetch_existing_products(
                    page=1,
                    page_size=page_size,
                    max_workers=max_workers,
                    fetch_mode=FetchMode.FROM_DATABASE,
                )
            else:
                print("Using existing products cache.")

        elif fetch_mode == FetchMode.FROM_DATABASE:

            pages = self.get_product_pages_count()
            # é€‰æ‹©ä¸€ä¸ªåˆç†çš„çº¿ç¨‹æ•°(è¶…è¿‡é¡µæ•°å°±æ²¡æœ‰å¿…è¦äº†,ä½†æ˜¯ä¹Ÿä¸èƒ½å°äº1)
            workers = self.get_worker_number(pages, max_workers)

            print(f"Fetching products with {workers} workers...")

            with ThreadPoolExecutor(max_workers=workers) as executor:
                futures = []
                for page in range(1, pages + 1):
                    futures.append(
                        executor.submit(self.get_product_page, page, page_size)
                    )
                for future in as_completed(futures):
                    response = future.result()
                    if not response.ok:
                        print(
                            f"Error fetching products: {self.get_code_message(response)}"
                        )
                        break
                    print(f"Parsing fetched products page {page}...")
                    products = response.json()
                    for product in products:
                        product_id = product.get("id")
                        name = product.get("name")
                        sku = product.get("sku")
                        if sku:
                            self.existing_products_sku[sku] = product_id
                        self.existing_products[product_id] = [name, sku]
                        print(
                            f"OK:Get product:{{id:{product_id};name:{name};sku:[{sku}]}}"
                        )
        elif fetch_mode == FetchMode.FROM_LOG_FILE:
            self.load_upload_log_data(log_file)
        else:
            print(f"Invalid mode: {fetch_mode}")
        # è¿”å›å€¼è¿˜å¯ä»¥é€‰æ‹©:self.existing_products_sku,self.existing_products
        # æˆ–è€…å¹²è„†ä¸è¿”å›å€¼,åé¢è¦ç”¨ç›´æ¥è®¿é—®ä¸¤ä¸ªå¯¹è±¡çš„ç¼“å­˜å®¹å™¨å±æ€§
        return self.existing_products

    def get_categories_page(self, page=1, page_size=100):
        """è·å–ç¬¬pageé¡µçš„åˆ†ç±»"""
        print(f"Fetching categories (page:{page})...")
        response = self.get(
            CATEGORIES_ENDPOINT, params={"per_page": page_size, "page": page}
        )
        if response.ok:
            print(f"OK:Get categories page {page}...")
        else:
            print(
                f"Failed:Fetch categories page {page}: {self.get_code_message(response)}"
            )
        return response

    def fetch_existing_categories(
        self, page=1, page_size=100, max_workers=5, mode=FetchMode.FROM_CACHE
    ):
        """è·å–æ‰€æœ‰ç°æœ‰åˆ†ç±»çš„åç§°å’ŒID

        å†…éƒ¨æœ‰ä¸€ä¸ªç»†èŠ‚,æ˜¯ç¼–ç å®ä½“å­—ç¬¦

        :param mode: è·å–æ¨¡å¼,é»˜è®¤ä¸ºFetchMode.FROM_CACHE,è¡¨ç¤ºä»ç¼“å­˜ä¸­è·å–,
        å¦‚æœé€‰æ‹©FetchMode.FROM_DATABASE,åˆ™è°ƒç”¨APIä»æ•°æ®åº“æŸ¥è¯¢è·å–, by default FetchMode.FROM_CACHE
        :param max_workers: æœ€å¤§çº¿ç¨‹æ•°, by default 5(å¦‚æœè®¾ç½®ä¸º0,è¡¨ç¤ºä¸ä½¿ç”¨å¤šçº¿ç¨‹æ¨¡å¼(é€é¡µè·å–))

        :return: åŒ…å«åˆ†ç±»åç§°å’ŒIDçš„å­—å…¸

        """
        if mode == FetchMode.FROM_CACHE:
            if not self.existing_categories:
                self.fetch_existing_categories(mode=FetchMode.FROM_DATABASE)
            # return self.existing_categories
        elif mode == FetchMode.FROM_DATABASE:
            categories_count = self.get_categories_page_count()
            workers = self.get_worker_number(categories_count, max_workers=max_workers)
            # åˆ†ç±»çš„é¡µæ•°ç»Ÿè®¡
            page = 1
            # å¤šçº¿ç¨‹æ–¹æ¡ˆ:è·å–åˆ†ç±»
            print(f"Fetching categories with {workers} workers...")
            with ThreadPoolExecutor(max_workers=workers) as executor:
                futures = [
                    executor.submit(self.get_categories_page, page, page_size)
                    for page in range(1, categories_count + 1)
                ]
                for future in as_completed(futures):
                    response = future.result()
                    # categories = response.json()
                    self.cache_categories_names(response)
            # æ™®é€šæ–¹æ¡ˆ: é€é¡µè·å–åˆ†ç±»
            if max_workers == 0:
                while True:

                    response = self.get_categories_page(page=page, page_size=page_size)
                    if not response.ok:
                        # apiè°ƒç”¨å¤±è´¥é€€å‡ºå¾ªç¯
                        print(
                            f"Failed to fetch categories: {self.get_code_message(response)}"
                        )
                        break
                    # è¿”å›åˆ†ç±»ä¸ºç©ºæ—¶é€€å‡ºå¾ªç¯
                    categories = response.json()
                    if not categories:
                        break

                    self.cache_categories_names(response)
                    page += 1
        return self.existing_categories

    def cache_categories_names(self, categories_page_response):
        """ç¼“å­˜åˆ†ç±»åç§°å’ŒID
        å¤„ç†åˆ†ç±»åç§°ç¼–ç 
        """
        if not categories_page_response.ok:
            print(
                f"Failed to fetch categories: {self.get_code_message(categories_page_response)}"
            )

            # return None
        else:
            categories = categories_page_response.json()
            for category in categories:
                # åˆ†ç±»åç§°è§£ç ä¸ºunicode(éƒ¨åˆ†å­—ç¬¦ä¼šè¢«ç¼–ç å­˜å‚¨,è§£ç åæ–¹ä¾¿æ¯”è¾ƒ)
                category_name_encoded = category["name"]
                category_name = html.unescape(category_name_encoded)
                self.existing_categories[category_name] = category["id"]

    def get_categories_count(self):
        """è·å–äº§å“åˆ†ç±»æ•°é‡"""
        # è·å–äº§å“åˆ†ç±»çš„ç¬¬ä¸€é¡µ(åŒ…å«æ€»æ•°ä¿¡æ¯)
        response = self.get(CATEGORIES_ENDPOINT, params={"per_page": 1})
        # ä» response.headers ä¸­è¯»å–æ€»æ•°ï¼ˆtotal number of categoriesï¼‰
        total_categories = response.headers.get("X-WP-Total")
        if total_categories:
            total_categories = int(total_categories)
        else:
            total_categories = -1
        return total_categories

    def get_categories_page_count(self, page_size=100):
        """è·å–äº§å“åˆ†ç±»é¡µæ•°"""
        total_categories = self.get_categories_count()
        pages = ceil(total_categories / page_size)
        return pages

    def get_product_page(self, page=1, page_size=100):
        """è·å–ç¬¬pageé¡µçš„äº§å“

        ä¸»è¦é…åˆfetch_existing_productsæ–¹æ³•ä½¿ç”¨

        Parameters
        ----------
        page : int, optional
            é¡µç , by default 1
        page_size : int, optional
            æ¯é¡µäº§å“æ•°é‡, by default 100
        return
            è¿”å›äº§å“åˆ—è¡¨çš„responseå¯¹è±¡,è°ƒç”¨è¿”å›å€¼çš„.jsonæ–¹æ³•è·å¾—åˆ—è¡¨æ•°æ®
        """
        # res = None
        print(f"Fetching products page {page}...")
        response = self.get(
            PRODUCTS_ENDPOINT, params={"per_page": page_size, "page": page}
        )
        if response.ok:
            print(f"OK:Get products page {page}...")
            # self.product_pages.append(response)
            # print(f"current products:{len(self.existing_products)}") #éœ€è¦åŠ é”æ‰èƒ½å‡†ç¡®è¯»å–
        else:
            print(
                f"Failed:Fetch products page {page}: {self.get_code_message(response)}"
            )
        return response

    def get_product_count_report(self):
        """è·å–äº§å“ç»Ÿè®¡æŠ¥å‘Š
        ç»Ÿè®¡æŠ¥å‘ŠåŒ…å«äº†äº§å“æ€»æ•°,ä¸åŒç±»å‹äº§å“çš„æ•°é‡,ä¸åŒçŠ¶æ€çš„äº§å“æ•°é‡ç­‰
        """
        res = self.get(PRODUCTS_TOTALS_ENDPOINT)
        if not res.ok:
            print(f"Failed to fetch products count: {self.get_code_message(res)}")
        return res

    def get_product_count(self, product_type="simple"):
        """è·å–äº§å“æ€»æ•°

        :param product_type: äº§å“ç±»å‹,é»˜è®¤ä¸º"simple",å¯ä»¥æŒ‡å®š"all"è·å–æ‰€æœ‰äº§å“ç±»å‹,ä¹Ÿå¯ä»¥æŒ‡å®šå…·ä½“ç±»å‹,æ¯”å¦‚"variable"è·å–å˜é‡äº§å“ç±»å‹
        :return:
            å¦‚æœæ˜¯å…·ä½“ç±»å‹,åˆ™è¿”å›äº§å“æ€»æ•°
            å¦åˆ™è¿”å›å…¨éƒ¨ç±»å‹çš„ç»Ÿè®¡æŠ¥å‘Šresponseå¯¹è±¡,è°ƒç”¨è¿”å›å€¼çš„.jsonæ–¹æ³•è·å¾—åˆ—è¡¨æ•°æ®

        è¾“å‡ºç¤ºä¾‹:(ä¸€èˆ¬æˆ‘ä»¬çœ‹çš„æ˜¯simpleç±»å‹çš„äº§å“)
        [{'slug': 'external', 'name': 'Prodotto Esterno/Affiliate', 'total': 0},
        {'slug': 'grouped', 'name': 'Grouped product', 'total': 0},
        {'slug': 'simple', 'name': 'Prodotto semplice', 'total': 143},
        {'slug': 'variable', 'name': 'Prodotto variabile', 'total': 0}]

        è¿”å›å€¼æ˜¯ä¸€ä¸ªç»Ÿè®¡æŠ¥å‘Šåˆ—è¡¨çš„response
        é€šè¿‡res[2]["total"]hunè·å–simpleç±»å‹çš„äº§å“æ€»æ•°
        æˆ–è€…é€šè¿‡æŒ‡å®šproduct_type="simple"è·å–æŒ‡å®šç±»å‹çš„äº§å“æ€»æ•°
        """

        print("Try get woocommerce prouducts count...")

        res = self.get_product_count_report()
        report = res.json()
        totoal = -1
        if res.ok:
            for d in report:
                if d.get("slug") == product_type:
                    totoal = d.get("total")
                    break
                    # print(totoal)
        else:
            print(f"Failed to fetch products count: {self.get_code_message(res)}")
        print(f"Total product count: {totoal}")
        return totoal

    def get_product_pages_count(self, page_size=100):
        """è·å–æ‰€æœ‰äº§å“çš„é¡µæ•°"""
        pages = ceil(self.get_product_count(product_type="simple") / page_size)
        return pages

    def load_upload_log_data(self, log_file):
        """ä»æ—¥å¿—æ–‡ä»¶ä¸­æ¢å¤å•†å“ä¸Šä¼ è¿›åº¦(è¯»æ¡£)
        æ—¥å¿—æ–‡ä»¶è¢«è®¾è®¡ä¸ºcsvæ ¼å¼,ä¸»è¦åŒ…å«SKU,Name,statusç­‰åˆ—
        ä¸»è¦ç­›é€‰å‡ºsku,nameè¿™ä¸¤åˆ—,åŒæ—¶ä»…ç­›é€‰ä¸Šä¼ æˆåŠŸçš„è®°å½•(OK)

        Note:
        å¦‚æœå‘ç°å¯¼å…¥çš„æ•°æ®é‡(è¡Œæ•°)å’Œlogæ–‡ä»¶ä¸­çš„è®°å½•æ•°ä¸ä¸€è‡´(OKè¡Œçš„è¡Œæ•°)ä¸ä¸€è‡´,å¯èƒ½æ˜¯ç”±äºè°ƒè¯•æœŸé—´äº§ç”Ÿçš„å…·æœ‰é‡å¤skuçš„è®°å½•,å­—å…¸(key)ä¼šè‡ªåŠ¨å»é‡(é¡¶æ›¿æ‰)
        """
        print(f"Loading upload log data from {log_file}...")
        with open(log_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                sku = row.get("SKU")
                name = row.get("Name")
                status = row.get("Status")
                product_id = row.get("id")
                # ä»æ—¥å¿—ä¸­è¯»å…¥æ“ä½œ(ä¸Šä¼ /æ›´æ–°)æˆåŠŸçš„è®°å½•
                if status == "OK":
                    self.existing_products_sku[sku] = product_id
                    self.existing_products[product_id] = [name, sku]
                # print(f"loading product: {sku};\tid:{product_id}; \tStatus: {status}")

    def get_custom_attribute(self, product_data, name="mycustom"):
        """è·å–(æ„é€ )è‡ªå®šå±æ€§æ•°æ®

        Parameters
        ----------
        product_data : dict
            ä¸€æ¡äº§å“æ•°æ®(ä¸€èˆ¬æ¥è‡ªcsvçš„ä¸€æ¡æ•°æ®)
        name : str, optional
            è‡ªå®šä¹‰çš„äº§å“å±æ€§å(å¯¹äºDFå›¢é˜Ÿé­”æ”¹çš„æƒ…å†µä¸‹,ä¸æ˜¯å¾ˆé‡è¦), by default "mycustom"

        Returns
        -------
        dcit
            æ„é€ çš„ç¬¦åˆwoocommerce apiè¦æ±‚çš„è‡ªå®šä¹‰å±æ€§æ•°æ®
        """
        # åˆ›å»ºè‡ªå®šä¹‰å±æ€§çš„å‡½æ•°
        name = product_data.get("Attribute 1 name")
        value = product_data.get("Attribute 1 value(s)", "")
        data = {
            "name": name,
            "slug": name,
            "visible": False,
            "options": [value],
        }
        # "type": "text",  # ä½¿ç”¨æ–‡æœ¬ç±»å‹å­˜å‚¨å®Œæ•´å€¼
        # "order_by": "menu_order",
        # "has_archives": False,
        if value:
            print(f"Creating custom attribute: {name}={value}")
        # è¿”å›å±æ€§æ•°æ®(åˆ—è¡¨)
        return [data]

    def process_tags(self, tags_str):
        """è·å–äº§å“æ ‡ç­¾åˆ—è¡¨
        å›¢é˜Ÿç›®å‰åªæœ‰ä¸€ä¸ªæ ‡ç­¾

        Parameters
        ----------
        tags_str : str
            csvä¸­çš„æ•°æ®è¡Œä¸­çš„æ ‡ç­¾å­—æ®µå­—ç¬¦ä¸²
        """
        if tags_str:
            tags_list = tags_str.split(",")  # æ ¹æ®é€—å·åˆ†éš”æ ‡ç­¾
            tags = [{"name": tag.strip()} for tag in tags_list]
            return tags
        else:
            return []

    def get_product_data(self, product_data) -> dict:
        """æ ¹æ®äº§å“æ•°æ®æ„é€ äº§å“å¯¹è±¡"""
        data = {}

        sku = product_data["SKU"]
        name = product_data["Name"]

        regular_price = product_data["Regular price"]
        sale_price = product_data["Sale price"]

        description = product_data["Description"]

        tags_str = product_data["Tags"]
        tags = self.process_tags(tags_str)

        # åˆ†ç±»(ç›®å‰çš„apiéœ€è¦å¾—åˆ°å¯¹åº”çš„id,æ¯”è¾ƒç‰¹æ®Š)
        # å›¢é˜Ÿä¸šåŠ¡è¦æ±‚åˆ†ç±»å¿…é¡»è¦æœ‰
        categories_str = product_data["Categories"]
        categories = self.get_categories(categories_str)

        # print(f"categories: {categories}")

        img_url = product_data["Images"]

        # å±æ€§å€¼è¦å°å¿ƒå¤„ç†
        attributes = self.get_custom_attribute(product_data)

        # attributes = product_data.get("Attributes", "")
        # attributes = self.parse_attributes(product_data)

        data = {
            "sku": sku,
            "type": "simple",
            "name": name,
            "regular_price": regular_price,
            "sale_price": sale_price,
            "description": description,
            "categories": categories,
            "Tags": tags,
            "images": [{"src": img_url}],
            "attributes": attributes,
        }
        if not data:
            raise ValueError("Product data is invalid.")
        return data

    def create_product(self, product_data):
        """åˆ›å»ºæ–°äº§å“

        è¿™é‡Œçš„product_dataå°†ä¼ é€’ç»™get_product_dataæ„é€ äº§å“å­—å…¸,åŒ…å«äº†å¿…è¦çš„äº§å“çš„ä¿¡æ¯
        """
        data = self.get_product_data(product_data)
        response = self.post("products", data)
        # try:
        # except TimeoutError:
        #     print(f"Timeout when creating product: {data.get('name')}")

        name = data["name"]
        sku = data["sku"]
        res_json = response.json()
        product_id = res_json.get("id")
        if response.ok:

            print(
                f"\tOK({self.progress_tracker.get_updated_progress_str()}):\
                    Product created:{{ Name:{name};sku:[{sku}] }}"
            )

            self.existing_products_sku[sku] = product_id
            self.existing_products[product_id] = [name, sku]
        else:
            print(f"Failed to create product: {self.get_code_message(response)}")

        return response

        # if sku not in self.existing_products_sku:
        #     # äº§å“ä¸Šä¸å­˜åœ¨,åˆ™ä¸Šä¼ æ–°äº§å“
        #     print(f"Uploading product: {name}")
        #     # print(f"\tCreating new product : {name}")

        #     # poståˆ›å»ºäº§å“ğŸˆ

    def update_product(self, product_data, update_mode="update_db_only"):
        """æ›´æ–°ç°æœ‰äº§å“

        :param product_data: äº§å“æ•°æ®å­—å…¸
        :param update_mode: æ›´æ–°æ¨¡å¼

            - é»˜è®¤ä¸º"update_db_only",è¡¨ç¤ºä»…æ›´æ–°æ•°æ®åº“ä¸­çš„äº§å“ä¿¡æ¯,ä¸æ›´æ–°WCå¯¹è±¡ç¼“å­˜;
            - å¦‚æœæ¨¡å¼ä¸º"refresh_product_cache",åˆ™è¿˜æ›´æ–°å¯¹åº”çš„ç¼“å­˜(self.existing_products)
        """
        data = self.get_product_data(product_data)
        sku = data["sku"]
        name = data["name"]
        if update_mode == "refresh_product_cache":
            # è·å–/æ›´æ–°å·²æœ‰äº§å“ç¼“å­˜
            self.fetch_existing_products()
        # id = self.existing_products_sku[sku]
        products = self.get_product(sku=sku)
        if products:
            product_id = products[0]["id"]
        else:
            raise ValueError("The id of the updating product not found.")

        response = self.put(f"{PRODUCTS_ENDPOINT}/{product_id}", data)

        if response.ok:
            print(f"\tOK:Product updated: {{Name:{name};SKU:{{{sku}}}}}")
        else:
            print(f"\tFailed to update product: {self.get_code_message(response)}")
        return response

    def get_batch_data(self, product_data_batch):
        """è·å–æ‰¹é‡æ“ä½œæ•°æ®
        ç›®å‰ä»…æä¾›åˆ›å»ºäº§å“çš„æ“ä½œæ‰€éœ€è¦çš„æ•°æ®æ ¼å¼
        åç»­æœ‰éœ€è¦çš„è¯å¯ä»¥æä¾›å…¶ä»–æ ¼å¼(åˆ é™¤/æ›´æ–°)
        """
        products_to_create = [
            self.get_product_data(product_data) for product_data in product_data_batch
        ]
        data = {
            "create": products_to_create,
            "update": [],
            "delete": [],
        }
        return data

        # for product_data in batch_data:

    def batch_update_products(self, batch, task_id=-1):
        """æ‰¹é‡æ“ä½œäº§å“
        æ›´æ–°å«ä¹‰ä¸ºå˜æ›´,åŒ…æ‹¬åˆ›å»º/æ›´æ–°/åˆ é™¤
        ä¸€ä¸ªè¯·æ±‚ä½“ä¸­å¯ä»¥åŒ…å«ä¸‰ç§æ“ä½œ(å¯¹åº”äºä¸‰ä¸ªæ•°ç»„)
        apié™åˆ¶æœ€å¤§batchä¸º100

        ç›®å‰ä»…æ‰¹é‡åˆ›å»ºäº§å“,åç»­å¯ä»¥æ‰©å±•åˆ°æ‰¹é‡æ›´æ–°/åˆ é™¤

        è¯¦æƒ…æŸ¥çœ‹api:https://woocommerce.github.io/woocommerce-rest-api-docs/#batch-update-products
        https://woocommerce.github.io/woocommerce-rest-api-docs/#batch-update-products

        Parameters
        ----------
        batch : dict
            æ‰¹é‡æ“ä½œçš„å­—å…¸,æ ¼å¼å‚è€ƒæ–‡æ¡£
        task_id : int, optional
            ä»»åŠ¡id,é»˜è®¤ä¸º-1(-1è¡¨ç¤ºæ²¡æœ‰è®¾ç½®)
        Returns
        -------
        responses : Response
            æ‰¹é‡æ“ä½œçš„å“åº”å¯¹è±¡
            batchä¸­åŒ…å«çš„æ¯ä¸€ç§æ“ä½œçš„å„ä¸ªåç§°å„æœ‰ä¸€ä¸ªåˆ—è¡¨
            Response.json()å’Œbatchç»“æ„ç›¸å¯¹åº”
        """
        print(f"batch update products task_id: {task_id} ...")
        batch_dict = self.get_batch_data(batch)
        response = Response()
        response.status_code = 504  # é»˜è®¤å€¼(è®¤ä¸ºæœåŠ¡å™¨é”™è¯¯)
        try:
            response = self.post(PRODUCT_BATCH_ENDPOINT, batch_dict)
            # è¿™é‡Œè·å–jsonçš„è¿‡ç¨‹ä¸­å¯èƒ½ä¼šå‡ºé”™,éœ€è¦æ•è·å¼‚å¸¸æˆ–æ”¾åœ¨tryä¸­
            res_json = self.get_response_json(response)
            # æ£€æŸ¥å“åº”ä½“ä¸­çš„ä¿¡æ¯
            # å°†æ¯ä¸ªäº§å“çš„ä¸Šä¼ æƒ…å†µæŒ‰ç…§çº¦å®šçš„æ—¥å¿—æ ¼å¼æ·»åŠ åˆ°æ—¥å¿—æ–‡ä»¶ä¸­
            # ç›®å‰ä»…å¤„ç†createæ“ä½œ
            res_creation_lst = res_json.get("create", [])
            # to verification
            for idx, info in enumerate(res_creation_lst):
                sku = batch[idx]["SKU"]
                name = batch[idx]["Name"]
                product_id = info.get("id")
                if product_id:
                    # å¯¹äºæ‰¹ä¸Šä¼ æ¨¡å¼,ä¸èƒ½åƒå•ä¸Šä¼ æ¨¡å¼é‚£æ ·ç›´æ¥æ ¹æ®å“åº”response.okåˆ¤æ–­æ˜¯å¦ä¸Šä¼ æˆåŠŸ,éœ€è¦æ£€æŸ¥å“åº”ä½“ä¸­çš„ä¿¡æ¯,æ¯”å¦‚åˆ¤æ–­idå­—æ®µæ˜¯å¦å­˜åœ¨
                    print(
                        f"OK{self.progress_tracker.get_updated_progress_str()}:\
                            create product:{{Name:{info.get('name')};SKU:[{info.get('sku')}]}}"
                    )
                    if not info.get("price"):
                        print(
                            f"Warning: product:{{Name:{info.get('name')};SKU:[{info.get('sku')}]}} has no price."
                        )
                        self.update_product(
                            batch[idx], update_mode="refresh_product_cache"
                        )
                    # æ·»åŠ åˆ°å·²æœ‰äº§å“ç¼“å­˜ä¸­
                    self.existing_products_sku[sku] = product_id
                    self.existing_products[product_id] = [name, sku]
                    # å†™å…¥æ—¥å¿—
                    log_upload(
                        sku,
                        name,
                        product_id=product_id,
                        status="OK",
                        msg="Product created.",
                    )
                else:
                    print(f"Failed: create product: {info.get('error')}")
                    log_upload(
                        sku,
                        name,
                        product_id=None,
                        status="Failed",
                        msg=info.get("error", ""),
                    )
        except Exception as e:
            print(f"Exception:Failed to batch update productsğŸ§¨: {e}")
            # å…¶ä»–æ“ä½œ...
        return response

    def get_response_json(self, response):
        """å®‰å…¨åœ°å°è¯•è§£æ JSON"""
        try:
            # æ‰“å°çŠ¶æ€ç å’Œæ–‡æœ¬å†…å®¹ï¼Œè¾…åŠ©è°ƒè¯•
            print("Status code:", response.status_code)
            res_json = response.json()
        except json.JSONDecodeError:
            print(
                "Failed to parse JSON. Response might be empty or not in JSON format."
            )
        return res_json

    def report_error_of_upload(self, name, sku, exception_message):
        """æ‰“å°ä¸Šä¼ å¤±è´¥çš„ä¿¡æ¯"""
        print(exception_message)
        print(f"Failed to create product:{{Name:{name};SKU:[{sku}];}}")

    def get_code_message(self, response, return_str=False):
        """è¯»å–responseå¯¹è±¡ä¸­çš„codeå’Œmessage
        ç›´æ¥ä»response.textè¯»å–çš„å€¼å¯èƒ½åŒ…å«\\uç¼–ç ,ä¸ä¾¿äºé˜…è¯»
        é€šè¿‡è°ƒç”¨json()æ–¹æ³•å¯ä»¥è·å¾—äººç±»å¯è¯»çš„unicodeå­—ç¬¦
        """
        res_json = response.json()
        code = res_json.get("code")
        msg = res_json.get("message")
        if return_str:
            return f"{code}:{msg}"
        return msg, code

    def upload_product(
        self,
        product_data,
        upload_mode=UPLOAD_MODE,
    ) -> Response:
        """ä¸Šä¼ äº§å“
        è¿™é‡Œå¤„ç†çš„æ˜¯å•ä¸ªäº§å“çš„ä¸Šä¼ ,è°ƒç”¨try_create_productæ¥ä¸Šä¼ 
        å…¶ä»–æ‰¹ä¸Šä¼ å¦è§å…¶ä»–ç›¸å…³å‡½æ•°

        :param product_data: äº§å“æ•°æ®å­—å…¸
        :param upload_mode: ä¸Šä¼ æ¨¡å¼,ä½¿ç”¨UploadModeçš„æšä¸¾å€¼



        """

        # å½“å‰ä¸Šä¼ çš„äº§å“çš„åŸºæœ¬ä¿¡æ¯
        sku = product_data["SKU"]
        name = product_data["Name"]
        # categories_str = product_data["Categories"]
        # print(f"processing product:{sku} {name}")
        res = Response()
        if upload_mode != "update_if_exist":
            # ä¸Šä¼ å¤±è´¥æ—¶ä¸å°è¯•æ›´æ–°äº§å“
            if self.existing_products_sku.get(product_data["SKU"]):
                # å¦‚æœå·²ç»å­˜åœ¨è¯¥äº§å“,åˆ™è·³è¿‡

                print(
                    f"Jump({self.progress_tracker.get_updated_progress_str()}):\
                        Product already exists: {{SKU:[{sku}]}}"
                )
                product_id = self.existing_products_sku.get(sku)
                res.status_code = 208
                # æŠŠè·³è¿‡çš„æƒ…å†µ(è¯´æ˜ç«™ç‚¹å·²ç»å­˜åœ¨è¯¥äº§å“,äºˆä»¥è·³è¿‡)
                # å°†è·³è¿‡çš„äº§å“å†™å…¥æ—¥å¿—(é‡‡ç”¨æ—¥å¿—é˜Ÿåˆ—å†™å…¥å¯èƒ½ä¼šé€ æˆæ•ˆç‡é—®é¢˜,æ¯”å¦‚å µå¡)
                log_upload(
                    sku=sku,
                    name=name,
                    product_id=product_id,
                    status="OK",
                    msg="Jump:Product already exist.",
                )
                # return res
            else:
                # å·²ä¸Šä¼ äº§å“çš„ç¼“å­˜ä¸­äº§å“ä¸å­˜åœ¨è¯¥äº§å“,å°è¯•åˆ›å»ºäº§å“(æ³¨æ„å¼‚å¸¸å¤„ç†)
                # print("ğŸˆtry create/upload product")
                self.try_create_product(product_data, upload_mode=upload_mode)
        elif upload_mode == "update_if_exist":
            # ç›´æ¥å°è¯•åˆ›å»ºäº§å“,ä¸ç®¡æ˜¯å¦å·²ç»æœ‰ç›¸åŒskuçš„äº§å“å­˜åœ¨,æ²¡æœ‰çš„è¯æ›´æ–°å·²æœ‰äº§å“
            self.try_create_product(product_data, upload_mode=upload_mode)
        # else:
        #     print(f"invalid upload_mode: {upload_mode}")
        return res

    def try_create_product(self, product_data, upload_mode=UPLOAD_MODE):
        """å°è¯•åˆ›å»ºäº§å“
        å¯¹create_productæ–¹æ³•è¿›è¡Œäº†å°è£…,å¢åŠ äº†å¼‚å¸¸å¤„ç†,å¹¶å¢åŠ äº†ä¸Šä¼ å¤±è´¥çš„äº§å“è®°å½•
        """
        sku = product_data["SKU"]
        name = product_data["Name"]
        try:
            res = self.create_product(product_data)
            # æ•°æ®åº“è¢«æ±¡æŸ“æˆ–è€…ç¼“å­˜ä¸å‡†ç¡®çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥é€‰æ‹©ä»¥æ›´æ–°çš„æ–¹å¼åˆ›å»ºäº§å“
            if upload_mode == "update_if_exist":
                # äº§å“å­˜åœ¨æ—¶,reså°†ä¼šè¿”å›é”™è¯¯ä»£ç ,å°è¯•æ£€æŸ¥é”™è¯¯ä»£ç ,å¦‚æœæœ‰åˆ™å°è¯•æ›´æ–°äº§å“
                if not res.ok:
                    print(f"Update:Product:{{Name:{name};SKU:[{sku}]}}")
                    # æ›´æ–°äº§å“
                    res = self.update_product(product_data)
            # å†™å…¥æ—¥å¿—æ–‡ä»¶(é’ˆå¯¹ä¸Šä¼ /æ›´æ–°æˆåŠŸçš„äº§å“)
            # if res.ok:
        except Exception as e:
            self.report_error_of_upload(
                name, sku, f"Exception (upload/update errorğŸ§¨): {e}"
            )
            # logging.error(f"Failed to create product: {name} (SKU: {sku}). Error: {e}")
            log_upload(sku, name, product_id=None, status="Failed", msg=str(e))
        else:
            # message=res.text
            # message = res_json.get("message")
            msg = str(self.get_code_message(res))

            if res.ok:
                # ä¸Šä¼ æˆåŠŸ,å†™å…¥æ—¥å¿—æ–‡ä»¶
                product_id = res.json().get("id")
                log_upload(
                    sku,
                    name,
                    product_id=product_id,
                    status="OK",
                    msg=msg,
                )
            else:
                # ä¸Šä¼ å¤±è´¥,å†™å…¥æ—¥å¿—æ–‡ä»¶
                log_upload(sku, name, product_id=None, status="Failed", msg=msg)
                # self.upload_failed_products.append((name, sku))

    def get_product(
        self,
        name=None,
        sku=None,
        product_id=None,
        category=None,
    ):
        """è·å–æŒ‡å®šäº§å“çš„ä¿¡æ¯

            woo apiä¸­å¯ç”¨çš„å‚æ•°ä¸å°‘,è¿™é‡Œä»…æ¥å…¥æœ€å¸¸ç”¨çš„å‡ ç§æƒ…å†µ,è¯¦ç»†åˆ—è¡¨å‚è€ƒæ–‡æ¡£
            list-all-products:
            https://woocommerce.github.io/woocommerce-rest-api-docs/?python#list-all-products
            å‡è®¾kæ˜¯åˆæ³•å‚æ•°å,è€Œvæ˜¯å¯¹åº”çš„é¢„æœŸå€¼,åˆ™WCå®ä¾‹(è®¾ä¸ºwc)çš„è°ƒç”¨æ–¹æ³•ä¸º
            wc.get(PRODUCTS_ENDPOINT,params={"k":v})

            é’ˆå¯¹äºæŸ¥æ‰¾æŒ‡å®šidçš„äº§å“,é‡‡ç”¨å¦ä¸€ä¸ªä¸“ç”¨api
            retrieve-a-product:
            https://woocommerce.github.io/woocommerce-rest-api-docs/?python#retrieve-a-product

        Parameters
        ----------
        product_name : str, optional
            äº§å“åç§°, by default None
        sku : str, optional
            äº§å“sku, by default None
        id : str, optional
            äº§å“id, by default None
        category : str, optional
            äº§å“åˆ†ç±»,å†…éƒ¨ä¼šå°è¯•è·å–id,ç„¶åè°ƒç”¨apiæŸ¥è¯¢, by default None
        Return
        -------
        list[dict]
            åŒ…å«äº§å“ä¿¡æ¯çš„åˆ—è¡¨,å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›ç©ºåˆ—è¡¨
        """
        res = []
        if name:
            # åˆ©ç”¨searchå‚æ•°æœç´¢äº§å“(è¿”å›åˆ—è¡¨)
            res = self.get(PRODUCTS_ENDPOINT, params={"search": name})
        elif sku:
            # æ ¹æ®skuè·å–äº§å“ä¿¡æ¯
            res = self.get(PRODUCTS_ENDPOINT, params={"sku": sku})
        elif category:
            cat_id = self.fetch_existing_categories(mode=FetchMode.FROM_CACHE).get(
                category
            )
            print(f"Get category id: {cat_id}")
            if not cat_id:
                print(f"Category: {category} not exist!")
            else:
                res = self.get(PRODUCTS_ENDPOINT, params={"category": cat_id})
        elif product_id:
            # æ ¹æ®idè·å–äº§å“ä¿¡æ¯
            # è¿™ä¸ªapiæ˜¯idæ£€ç´¢ä¸“ç”¨,è¿”å›çš„æ˜¯å•ä¸ªäº§å“ä¿¡æ¯,response.json()è¿”å›çš„æ˜¯å­—å…¸
            res = self.get(f"{PRODUCTS_ENDPOINT}/{product_id}")
            if res.ok:
                res = [res.json()]
            else:
                print(f"Failed to get product: {product_id}")
        else:
            print("No valid parameters provided.")
        # ä»responseä¸­è§£æå‡ºå­—å…¸åˆ—è¡¨
        if isinstance(res, Response):
            # res = list(res)
            res = res.json()
        return res

    def delete_product(
        self, category=None, name=None, product_id=None, sku=None, force=True
    ):
        """
        åˆ é™¤æŒ‡å®šçš„äº§å“ã€‚
        è¿™äº›å‚æ•°ä»…èƒ½é€‰æ‹©å…¶ä¸­ä¸€ä¸ª,å¦åˆ™ä¼šæŠ¥é”™ã€‚


        :param category: äº§å“çš„åˆ†ç±»ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœæä¾›ï¼Œåˆ™æ ¹æ®åˆ†ç±»åˆ é™¤äº§å“ã€‚
        :param name: äº§å“çš„åç§°ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœæä¾›ï¼Œåˆ™æ ¹æ®åç§°æœç´¢äº§å“å¹¶åˆ é™¤ã€‚
        :param id: äº§å“çš„ IDï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœæä¾›ï¼Œåˆ™ç›´æ¥åˆ é™¤è¯¥äº§å“ã€‚
        :param sku: äº§å“çš„ SKUï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœæä¾›ï¼Œåˆ™æ ¹æ® SKU æŸ¥æ‰¾äº§å“ ID å¹¶åˆ é™¤ã€‚
        :param force: æ˜¯å¦å½»åº•åˆ é™¤äº§å“(True),è‹¥è®¾ç½®ä¸ºFalse,åˆ™ä»…ç§»å…¥å›æ”¶ç«™(å›¢é˜Ÿä¸šåŠ¡ä¸€èˆ¬è¦åˆ é™¤å°±æ˜¯å½»åº•åˆ é™¤)

        :return: list[response]   å¦‚æœæƒ³è¦æŸ¥çœ‹è¢«åˆ é™¤çš„äº§å“çš„åå­—,å¯ä»¥å°†æ­¤è¿”å›å€¼(åˆ—è¡¨)éå†,è°ƒç”¨.json()æ–¹æ³•,ç„¶åè®¿é—®"name"å­—æ®µå³å¯
        """
        products = self.get_product(
            category=category, name=name, product_id=product_id, sku=sku
        )
        # å¦‚æœç”¨æˆ·æä¾›çš„æ˜¯sku,é‚£ä¹ˆæ ¹æ®apiçš„è¦æ±‚,æˆ‘ä»¬è¦å…ˆæ‰¾åˆ°å¯¹åº”çš„äº§å“id;æœ€ç»ˆéƒ½æ˜¯é€šè¿‡idæ¥åˆ é™¤æŒ‡å®šäº§å“
        # if sku:

        #     self.get_product(sku=sku)

        # if not self.existing_products:
        #     self.fetch_existing_products()
        # product_id = self.existing_products.get(sku)
        # if not product_id:
        #     print(f"Product with SKU '{sku}' not found.")
        #     return None
        # è°ƒç”¨apiåˆ é™¤äº§å“
        deleted_products = []
        if products:
            # print(type(products))
            # print(products[0])
            for product in products:
                # product=product.json()

                product_id = product["id"]
                name = product["name"]
                print(f"Try to delete product with ID: {product_id}")
                response = self.delete(
                    f"products/{product_id}", params={"force": force}
                )
                if response.ok:
                    print(
                        f"Delete:product [ID:{product_id};SKU:[{sku}]];\
                            Name:{name} deleted successfully."
                    )
                    # å°†åˆ é™¤æˆåŠŸçš„å“åº”å€¼åŠ å…¥åˆ°å·²åˆ é™¤åˆ—è¡¨
                    deleted_products.append(response)
                    # ä»ç°æœ‰äº§å“ç¼“å­˜ä¸­åˆ é™¤è¯¥äº§å“
                    self.existing_products.pop(product_id, None)
                    if not sku:
                        sku = product.get("sku")
                    self.existing_products_sku.pop(sku, None)

                else:
                    print(
                        f"Failed to delete product with ID \
                            {product_id}: {self.get_code_message(response)}"
                    )

        return deleted_products

    def delete_batch_products(self, ids):
        """
        æ‰¹é‡åˆ é™¤äº§å“ã€‚
        ä¼ å…¥ä¸€ä¸ªidåˆ—è¡¨,æ‰¹é‡åˆ é™¤å¯¹åº”çš„äº§å“
        """
        for product_id in ids:
            self.delete_product(product_id=product_id)

    def delete_all_products(self, max_workers=50):
        """
        åˆ é™¤æ‰€æœ‰äº§å“ã€‚
        é€šè¿‡éå†æ‰€æœ‰äº§å“,ç„¶åé€ä¸ªåˆ é™¤(è°ƒç”¨delete_productæ–¹æ³•)
        """

        self.fetch_existing_products(fetch_mode=FetchMode.FROM_DATABASE)
        if not self.existing_products:
            print("No products found.")
        # éå†å­—å…¸(è¿™é‡Œéå†keyså³å¯)
        products_count = self.get_product_count()
        products = copy.deepcopy(self.existing_products)
        workers = self.get_worker_number(products_count, max_workers)
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = [
                executor.submit(self.delete_product, product_id=id)
                for id in products.keys()
            ]
            for future in as_completed(futures):
                future.result()

    def upload_rows(
        self,
        rows,
        upload_mode=UPLOAD_MODE,
    ):
        """ä¸Šä¼ è‹¥å¹²è¡Œæ•°æ®

        :param rows:è¦ä¸Šä¼ çš„äº§å“æ•°æ®åˆ—è¡¨
        """
        for row in rows:
            self.upload_product(row, upload_mode=upload_mode)

    def get_products_need_to_uploaded(
        self, csv_files=files, fetch_mode=FetchMode.FROM_DATABASE
    ):
        """è·å–è¿˜æœªä¸Šä¼ çš„äº§å“"""
        # to verify
        if not self.product_from_file:
            self.product_from_file = self.get_rows_from_csvs(csv_files)
        if not self.existing_products_sku:
            self.fetch_existing_products(fetch_mode=fetch_mode)
        # ä»¥æ¥è¿‘O(n)çš„æ—¶é—´å¤æ‚åº¦è®¡ç®—è¿˜æœªä¸Šä¼ çš„äº§å“(åˆ©ç”¨å“ˆå¸Œè¡¨çš„å¿«é€ŸæŸ¥æ‰¾ç‰¹æ€§,æŠŠO(nxm)é™ä½åˆ°O(n))
        for product_data in self.product_from_file:
            sku = product_data.get("SKU")
            if not self.existing_products_sku.get(sku, None):
                self.products_need_to_upload.append(product_data)
                print(f"Found:Product with SKU '{sku}' need to upload")
            else:
                print(f"Jump:Product with SKU '{sku}' already exist.")
        return self.products_need_to_upload

    def get_rows_from_csv(self, csv_file):
        """ä» CSV æ–‡ä»¶è¯»å–æ•°æ®

        è¿”å›ä¸€ä¸ªåˆ—è¡¨,åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸,å­—å…¸çš„é”®æ˜¯CSVæ–‡ä»¶ä¸­çš„åˆ—å,å€¼æ˜¯è¯¥åˆ—çš„å€¼ã€‚"""
        print(f"process_csv: {csv_file}...")
        rows = []
        with open(csv_file, mode="r", encoding="utf-8") as file:
            reader = csv.DictReader(file)
            rows = list(reader)
            # å°†è¯»å–åˆ°çš„csvæ–‡ä»¶ç¼“å­˜åˆ°wcç¤ºä¾‹ä¸­,ä¾¿äºåç»­ä½¿ç”¨
            # self.product_data_from_file += rows
        return rows

    def get_rows_from_csvs(self, csv_files):
        """ä» CSV æ–‡ä»¶åˆ—è¡¨è¯»å–æ•°æ®"""
        for file in csv_files:
            self.product_from_file += self.get_rows_from_csv(file)
        return self.product_from_file

    def orderd_concurrent_execute(self, max_workers, upload_mode, rows):
        """æ™®é€šçš„å¤šçº¿ç¨‹æ¨¡å¼,æœ‰åºå‘å°„
        è¯¥æ¨¡å¼ä¸‹,æ‰€æœ‰çº¿ç¨‹çš„å¹¶å‘æ‰§è¡Œé¡ºåºæ˜¯æŒ‰ç…§csvæ–‡ä»¶çš„é¡ºåºæ‰§è¡Œçš„,å³:å…ˆä¸Šä¼ ç¬¬ä¸€è¡Œ,å†ä¸Šä¼ ç¬¬äºŒè¡Œ,ä¾æ¬¡ç±»æ¨ã€‚(ä½†æ˜¯å…ˆä¸Šä¼ çš„ä¸ä¸€å®šå…ˆå®Œæˆ,è¿™æ˜¯å¤šçº¿ç¨‹å¼‚æ­¥æ‰§è¡Œçš„ç‰¹ç‚¹)

        è¯¥æ¨¡å¼ä»£ç ç®€å•,è€Œä¸”å®¹æ˜“å‘ç°å¡ä½çš„åœ°æ–¹
        ä¸è¶³å°±æ˜¯å®¹æ˜“é›†ä¸­è¯·æ±‚è¢«é‡‡é›†ç«™çš„æœåŠ¡å™¨,æ›´æœ‰å¯èƒ½è¢«å°(ban)
        æ›´å¥½çš„æ–¹æ³•æ˜¯åœ¨ä¸Šä¼ å‰è¿›è¡ŒéšæœºåŒ–æ’åº,(ç”šè‡³å¯ä»¥åˆ©ç”¨pandasé‡æ–°æ’åˆ—skuç¼–å·)

        Parameters
        ----------
        max_workers : int
            çº¿ç¨‹æ± å†…çš„çº¿ç¨‹æ•°
        upload_mode : str
            ä¸Šä¼ æ¨¡å¼:
        rows : list[dict]
            ä»æ–‡ä»¶è¯»å–çš„è¦ä¸Šä¼ çš„äº§å“æ•°æ®
        """
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [
                executor.submit(self.upload_product, row, upload_mode=upload_mode)
                for row in rows
            ]
            for future in as_completed(futures):
                future.result()

    def partition_concurrent_execute(self, max_workers, upload_mode, rows):
        """åˆ†åŒºå¹¶å‘æ‰§è¡Œ,å¯ä»¥æ›´åŠ ç›´è§‚çš„çœ‹åˆ°å¹¶å‘çš„è¿è¡Œè¿‡ç¨‹,ç›¸æ¯”äºæ™®é€šçš„å¹¶å‘æ¨¡å¼,æ›´æœ‰åˆ©äº(æ›´æœ‰å¯èƒ½)å‡è½»å¯¹åŒä¸€ä¸ªé‡‡é›†ç«™çš„å¹¶å‘è¯·æ±‚å‹åŠ›(ä¸»è¦æ˜¯å›¾ç‰‡è¯·æ±‚,ä½†ä¸»è¦è¿˜æ˜¯è¦æ§åˆ¶æ± å†…çº¿ç¨‹æ•°)

        æ­¤æ¨¡å¼çš„ç¼ºç‚¹ä¸»è¦æ˜¯å¦‚æœä¸­æ–­çš„è¯ç›¸å¯¹æ™®é€šçš„æœ‰åºå‘å°„,è¾ƒéš¾å®šä½ä¸Šä¼ å¡ä½çš„æ•°æ®ä½äºé‚£ä¸€ä»½æ–‡ä»¶ç¬¬å‡ æ¡

        Parameters
        ----------
        max_workers : int
            çº¿ç¨‹æ± å†…çš„çº¿ç¨‹æ•°
        upload_mode : str
            ä¸Šä¼ æ¨¡å¼:å‚è€ƒè°ƒç”¨è€…å‡½æ•°çš„æ–‡æ¡£
        rows : list[dict]
            ä»æ–‡ä»¶è¯»å–çš„è¦ä¸Šä¼ çš„äº§å“æ•°æ®
        """
        batches = split_list(rows, max_workers)
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [
                executor.submit(self.upload_rows, batch, upload_mode=upload_mode)
                for batch in batches
            ]
            # for future in as_completed(futures):
            for future in as_completed(futures):
                future.result()

            # for row in reader:
            #     self.upload_product(product_data=row, upload_mode=upload_mode)

    def batch_concurrent_execute(self, max_workers, rows):
        """æŒ‰æ‰¹æ„é€ æ•°æ®å‘é€,èŠ‚çº¦è¯·æ±‚æ¬¡æ•°å’Œç½‘ç»œè¿æ¥æ•°å‹åŠ›(æœåŠ¡å™¨ç«¯å‹åŠ›å¯èƒ½æ¯”è¾ƒå¤§)

        Parameters
        ----------
        max_workers : int
            çº¿ç¨‹æ± å†…çš„çº¿ç¨‹æ•°
        upload_mode : str
            ä¸Šä¼ æ¨¡å¼:(å¾…å°†æ¥æ‰©å±•)
        rows : list[dict]
            è¦ä¸Šä¼ çš„äº§å“æ•°æ®
        """
        # batch_number=ceil(len(rows)/BATCH_SIZE)
        print(
            f"Batch Mode:upload {len(rows)} products in batches with  {max_workers} threads..."
        )
        batches = [rows[i : i + BATCH_SIZE] for i in range(0, len(rows), BATCH_SIZE)]
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [
                executor.submit(self.batch_update_products, batch, idx)
                for idx, batch in enumerate(batches)
            ]
            for future in as_completed(futures):
                future.result()

    def process_csv(
        self,
        csv_file=r"",
        filtered_rows=(),
        max_workers=5,
        upload_mode=UPLOAD_MODE,
        batch_mode=True,
    ):
        """ä» CSV æ–‡ä»¶è¯»å–æ•°æ®å¹¶ä¸Šä¼ äº§å“
        å¤„ç†å•ä¸ªcsvæ–‡ä»¶

        :param csv_file csvæ–‡ä»¶è·¯å¾„,è¯·ä½¿ç”¨r""å­—ç¬¦ä¸²,è¿™æ ·å…¼å®¹æ­£åæ–œæ 
        :param filtered_rows: è¿‡æ»¤åçš„äº§å“æ•°æ®åˆ—è¡¨,ç”¨äºè·³è¿‡å·²å­˜åœ¨çš„äº§å“çš„æ–¹æ¡ˆ
        :param max_workers: å¹¶å‘çº¿ç¨‹æ•°
        :param upload_mode: ä¸Šä¼ æ¨¡å¼
        :param batch_mode: æ˜¯å¦ä½¿ç”¨åˆ†æ‰¹æ„é€ æ•°æ®å‘é€çš„æ¨¡å¼

        :return: None

        æ–¹æ¡ˆ1:åˆ†åŒºå¹¶å‘
        å°†csvæ–‡ä»¶å¹³å‡åˆ†ä¸ºmax_workersä»½,æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€ä»½
        self.partition_concurrent_execute(max_workers, upload_mode, rows)

        æ–¹æ¡ˆ2:æœ‰åºå‘å°„æ¨¡å¼
        self.orderd_concurrent_execute(max_workers, upload_mode, rows)

        æ–¹æ¡ˆ3:åˆ†æ‰¹æ„é€ æ•°æ®å‘é€
        self.batch_concurrent_execute(max_workers, rows)

        """
        # è¯»å–æ‰€æœ‰csvæ–‡ä»¶,å°†æ‰€æœ‰åˆ†ç±»æ•´ç†å‡ºæ¥,ç„¶ååœ¨ä¸Šä¼ æ•°æ®å‰æå‰åˆ›å»ºå¥½åˆ†ç±»,å¯ä»¥å…å»åé¢çš„åˆ†ç±»æ£€æŸ¥å·¥ä½œ,ä¹Ÿæœ‰åˆ©äºé™ä½å¤šçº¿ç¨‹çš„å¤„ç†å¤æ‚åº¦
        rows = []
        if csv_file:
            rows = self.get_rows_from_csv(csv_file)
        elif filtered_rows:
            rows = filtered_rows
        else:
            print("No data need to upload Or empty parameters provided.")
        # æ ¹æ®éœ€è¦é€‰æ‹©ä¸Šé¢çš„æ–¹æ¡ˆ
        if batch_mode:
            self.batch_concurrent_execute(max_workers, rows)
        else:
            self.orderd_concurrent_execute(max_workers, upload_mode, rows)

    def process_csvs(self, *args, **kwargs):
        """
        å®‰å…¨çš„csvå¤„ç†å‡½æ•°,ç”¨äºé˜²æ­¢å› ä¸ºå¼‚å¸¸å¯¼è‡´ç¨‹åºä¸­æ–­
        """
        try:
            self._process_csvs(*args, **kwargs)
        except Exception as e:
            logging.error(f"Error occurred in {e}")

    def _process_csvs(
        self,
        csv_files: list[str] = files,
        max_workers=MAX_WORKERS_FILES,
        upload_mode=UPLOAD_MODE,
        batch_mode=True,
        filtered_mode=True,
        prepare_categories=True,
        log_file="",
    ):
        """ä» CSV æ–‡ä»¶åˆ—è¡¨è¯»å–æ•°æ®å¹¶ä¸Šä¼ äº§å“
        å¤„ç†å¤šä¸ªcsvæ–‡ä»¶
        ä½¿ç”¨self.products_need_to_uploadæ¥ç›´æ¥è·³è¿‡å·²å­˜åœ¨çš„äº§å“çš„æ–¹æ¡ˆæ—¶,
        å¯ä»¥ç”¨é€‚å½“çš„å‚æ•°è‡ªè¡Œåˆ†è¢«è°ƒç”¨self.get_products_need_to_uploaded()å’Œself.process_csv()

        :param csv_files  csvæ–‡ä»¶åˆ—è¡¨,ä½¿ç”¨r""å­—ç¬¦ä¸²,è¿™æ ·å…¼å®¹æ­£åæ–œæ 
        :param max_workers: å¹¶å‘çº¿ç¨‹æ•°
        :param upload_mode: ä¸Šä¼ æ¨¡å¼,ä½¿ç”¨UploadModeä¸­çš„æšä¸¾å€¼
        :param batch_mode: æ˜¯å¦ä½¿ç”¨åˆ†æ‰¹æ„é€ æ•°æ®å‘é€çš„æ¨¡å¼(é»˜è®¤ä½¿ç”¨,å¯ä»¥é™ä½è¯·æ±‚å‹åŠ›,é™ä½å‘ç”Ÿ:
            - [WinError 10055] ç”±äºç³»ç»Ÿç¼“å†²åŒºç©ºé—´ä¸è¶³æˆ–é˜Ÿåˆ—å·²æ»¡ï¼Œä¸èƒ½æ‰§è¡Œå¥—æ¥å­—ä¸Šçš„æ“ä½œçš„é”™è¯¯)
        :param filtered_mode: æ˜¯å¦é¢„å…ˆè¿‡æ»¤/è®¡ç®—å‡ºè¿˜æœªè¢«ä¸Šä¼ çš„äº§å“æ•°æ®(è·³è¿‡å·²å­˜åœ¨çš„äº§å“,å‡å°‘ä¸å¿…è¦çš„è¯·æ±‚æ¬¡æ•°)
            è¿™æ˜¯æ¨èä½¿ç”¨çš„,æ ·æ‰¹ä¸Šä¼ æ¨¡å¼ä¹Ÿå¯ä»¥è½»æ¾è·³è¿‡å·²ä¸Šä¼ çš„æ•°æ®
            å¦‚æœè®¾ç½®ä¸ºFalse,å°†åˆ†æ–‡ä»¶ä¸Šä¼ 
        :param prepare_categories: æ˜¯å¦é¢„å…ˆå‡†å¤‡åˆ†ç±»

            æ ¹æ®éœ€è¦çµæ´»é€‰æ‹©,ä¾‹å¦‚ä½ è¦æ£€æŸ¥åˆ†ç±»ä¸Šä¼ åä¼šä¸ä¼šè¢«é”™è¯¯ç¼–ç ,åˆ™ä½¿ç”¨True;
            å¦‚æœä½ å¸Œæœ›ä¸Šä¼ ç¬¬ä¸€æ¡äº§å“åèƒ½å¤Ÿå°½æ—©çœ‹åˆ°äº§å“åˆ—è¡¨ä¸­çš„äº§å“,åˆ™ä½¿ç”¨False

            - å¦‚æœè®¾ç½®ä¸ºFalse
            ä¸ä¼šé¢„å…ˆæ£€æŸ¥äº§å“åˆ†ç±»,åœ¨ä¸Šä¼ æ•°æ®æ—¶æ£€æŸ¥è¯¥æ¡äº§å“æ•°æ®,å¦‚æœåˆ†ç±»ä¸å­˜åœ¨,åˆ™åˆ›å»º,å¦åˆ™ç›´æ¥è¿”å›åˆ†ç±»id
            - å¦‚æœè®¾ç½®ä¸ºTrue
            ä¼šåœ¨ä¸Šä¼ äº§å“ä¹‹å‰,å…ˆå°†åˆ†ç±»æ•´ç†å¹¶åˆ›å»ºå¥½(è°ƒç”¨prepare_categoriesæ–¹æ³•);
        :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„,ç”¨äºè®°å½•å·²ä¸Šä¼ çš„äº§å“æ•°æ®,å½“upload_modeä¸ºUploadMode.RESUME_FROM_LOG_FILEæ—¶,éœ€è¦æŒ‡å®šè¯¥å‚æ•°

        """

        # æ£€æŸ¥è·¯å¾„å‚æ•°(å¦‚æœæœ‰çš„è¯)
        if log_file and not os.path.exists(log_file):
            logging.error(f"Log file '{log_file}' not found.")
            sys.exit(-1)
        # æ˜¯å¦äº‹å…ˆå‡†å¤‡å¥½åˆ†ç±»
        if prepare_categories:
            self.prepare_categories(csv_files)
        else:
            print(
                "Mutex Lock Mode:check and create categories when data row was uploading..."
            )
        # ä¸Šä¼ æ¨¡å¼/ç­–ç•¥:è¯»æ¡£(æ¢å¤ä¸Šä¼ è¿›åº¦æ–¹æ¡ˆ)
        if upload_mode == UploadMode.RESUME_FROM_DATABASE:
            # å°è¯•ä»wpç«™æ•°æ®åº“ä¸­è¯»å–å·²ä¸Šä¼ çš„æ•°æ®,å¹¶å†™å…¥ç¼“å­˜å®¹å™¨
            self.fetch_existing_categories()  # mode=FetchMode.FROM_DATABASE
            self.fetch_existing_products()
        elif upload_mode == UploadMode.RESUME_FROM_LOG_FILE:
            # ä»æ—¥å¿—æ–‡ä»¶ä¸­è¯»å–å·²ä¸Šä¼ çš„æ•°æ®,å¹¶å†™å…¥ç¼“å­˜å®¹å™¨
            # to verify
            self.fetch_existing_products(
                fetch_mode=FetchMode.FROM_LOG_FILE, log_file=log_file
            )

        # æ•°æ®æ–‡ä»¶å¤„ç†å’Œä¸Šä¼ ç­–ç•¥(å¹¶å‘æ–¹å¼)
        ## æ–¹æ¡ˆ1:è®¡ç®—å‡ºå°šæœªä¸Šä¼ çš„äº§å“(é›†ä¸­å¤„ç†)
        if filtered_mode:
            self.get_products_need_to_uploaded(csv_files)
            self.process_csv(
                filtered_rows=self.products_need_to_upload,
                max_workers=max_workers,
                upload_mode=upload_mode,
                batch_mode=batch_mode,
            )
        else:
            # æ–¹æ¡ˆ2:é€ä¸ªæ–‡ä»¶å¤„ç†(åˆ†æ•£å¤„ç†)
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(
                        self.process_csv,
                        file,
                        max_workers=MAX_WORKERS_PER_FILE,
                        upload_mode=upload_mode,
                        batch_mode=batch_mode,
                    )
                    for file in csv_files
                ]
                for future in as_completed(futures):
                    future.result()


##

# ä¸»å‡½æ•°
if __name__ == "__main__":

    # å¯åŠ¨åå°æ—¥å¿—çº¿ç¨‹
    log_thread = threading.Thread(target=log_worker, daemon=True)
    log_thread.start()

    wc = WC()
    # æ£€æŸ¥wooé‰´æƒå’Œé“¾æ¥(è¿”å›-1è¡¨ç¤ºé“¾æ¥å¤±è´¥)
    wc.get_product_count()

    # æ‹‰å–ç¼“å­˜æ•°æ®(äº§å“æ•°æ®/åˆ†ç±»),å¯¹äºéçº¯å‡€ä¸Šä¼ æ¨¡å¼å»ºè®®æ‰§è¡Œä¸‹é¢è¯­å¥
    # wc.fetch_existing_products(max_workers=15,mode=FetchMode.FROM_DATABASE)
    # wc.fetch_existing_categories()

    # æ¸…ç©ºæ‰€æœ‰äº§å“(å¯¹äºå¹²å‡€ä¸Šä¼ ,å¯ä»¥æ¸…é™¤æ¨¡æ¿ä¸­è‡ªå¸¦çš„å•†å“)
    # wc.delete_all_products()

    # æ™®é€šæ‰§è¡Œ(å¹²å‡€ä¸Šä¼ )
    # wc.process_csvs(
    #     files,
    #     max_workers=MAX_WORKERS_FILES,
    #     upload_mode=UPLOAD_MODE,
    #     prepare_categories=True,
    #     batch_mode=True,
    # )

    # ä»æ—¥å¿—æ–‡ä»¶ä¸­æ¢å¤ä¸Šä¼ è¿›åº¦
    # wc.process_csvs(
    #     files,
    #     max_workers=MAX_WORKERS_FILES,
    #     upload_mode=UploadMode.RESUME_FROM_LOG_FILE,#å¦‚æœè¦ä»æ•°æ®åº“ä¸­æ¢å¤,åˆ™ä½¿ç”¨UploadMode.RESUME_FROM_DATABASE
    #     prepare_categories=True,
    #     batch_mode=True,
    #     log_file=r"" #å¡«å†™æ­£ç¡®çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„
    # )

    # ç»“å°¾æ¸…ç†log_thread(é€‚åˆäºä»å‘½ä»¤è¡Œä¸­æ‰§è¡Œæ—¶ä½¿ç”¨)
    # cleanup_log_thread(log_thread)
